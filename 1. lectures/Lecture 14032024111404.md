---
tags:
  - category/lecture
  - status/finished
  - topic/algebra-e-geometria
date: 14-03-2024 11:14:04
teacher: marta.morigi@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- attenzione: mercoledì 3 aprile o 27 marzo _autovalutazione_
	- è una simulazione d'esame (parziale), che vi viene corretta ma non ha peso
	- ce ne sono già su dynamik, ma quest'anno saranno più leggeri <--> circa come i fogli di tutoraggio
	- ci mette anche qualcosa sulle applicazioni lineari
- [[Applicazione lineare|applicazioni lineari]]
	- ripasso della definizione
	- proposizione: $f$ è lineare $\implies f(0_{V}) = 0_{W}$, ovvero _mappatura dell'elemento neutro_
		- dimostrazione: $f(0_{V}) = f(0 \cdot 0_{V}) = 0 \cdot f(0_{V}) = 0_{W}$ (perché $f(0_{V})$ è un vettore di $W$)
		- conseguenza: $f: \mathbb{R}^{3} \to \mathbb{R}^{2}$ t.c. $(x_{1}, x_{2}, x_{3}) \to (2x_{2}, x_{1}-x_{3}+1)$ non è lineare, perché $f(0, 0) = (2 \cdot 0, 0 - 0 + 1) = (0, 1) \neq (0, 0)$
	- ricordiamo cosa importantissima
		- $L_{A}: \mathbb{R}^{n} \to \mathbb{R}^{m}$ t.c. $\underline{x} \to A \underline{x}$
		- ha la proprietà delle colonne...
		- vedremo che tutte le applicazioni da $\mathbb{R}^{n}$ a $\mathbb{R}^{m}$ sono tutte fatte come $L_{A}$
	- preambolo
		- $A, B$ insiemi, allora $f: A \to B$ e l'[[Immagine di funzione|immagine]] $\Im(f) = \{f(a) | a \in A\}$, oppure $\Im(f) = \{b \in B | \exists a \in A. b = f(a)\}$
			- $f$ si dice suriettiva se $\Im(f) = B$
			- $f$ si dice iniettiva se $a_{1} \neq a_{2} \implies f(a_{1}) \neq f(a_{2})$, che equivale alla sua contronominale $f(a_{1}) = f(a_{2}) \implies a_{1} = a_{2}$
	- definizione (da preambolo): $f: V \to W$ lineare, si ha che il **kernel** (o **nucleo**) $$\ker(f) = \{v \in V | f(v) = \underline{0}\}$$
		- proposizione: $f: V \to W$ lineare, si ha che
			- $\ker(f) \leq V$
				- dimostrazione
					1. $0_{V} \in \ker(f)$, perciò devo verificare $f(0_{V}) = 0_{W} \implies 0_{V} \in \ker(f)$
					2. $v_{1}, v_{2} \in \ker(f)$ quindi $f(v_{1}) = \underline{0}, f(v_{2}) = \underline{0}$, allora $f(v_{1} + v_{2}) \in \ker(f)?$ Uso la linearità di $f$, per cui $f(v_{1} + v_{2}) = f(v_{1}) + f(v_{2}) = \underline{0} + \underline{0} = \underline{0} \implies \in \ker(f)$
					3. $v \in \ker(f), \lambda \in \mathbb{R}$ quindi $f(v) = \underline{0}$, allora $\lambda v \in \ker(f)?$ Uso linearità di $f$, per cui $f(\lambda v) = \lambda f(v) = \lambda \underline{0} = \underline{0} \implies \in \ker(f)$
			- $\Im(f) \leq W$
		- proposizione: $f: V \to W$ lineare
			1. $f$ è suriettiva $\iff$ $\Im(f) = W$
				- vera per definizione
			2. $f$ è iniettiva $\iff$ $\ker(f) = \{\underline{0}\}$
				- dimostro 1° verso: $f$ è iniettiva, prendo $v \in \ker(f)$ ovvero $f(v) = \underline{0} = f(0_{V})$, e per cui se $f$ è iniettiva devo avere $v = 0_{V} \implies \ker(f) = \{0_{V}\}$
				- dimostro 2° verso: $\ker(f) = \{\underline{0}\}$, mostro $f$ è iniettiva usando la contronominale, perciò $f(u) = f(v) \implies u = v$; se $f(u) = f(v) \implies f(u) - f(v) = \underline{0}$, per cui per la linearità di $f$ ho che $f(u-v) = \underline{0}$: ho trovato il vettore $u-v$ che sta in $\ker(f)$, per cui $u-v = \underline{0} \implies u = v$
		- osservazione: $f$ lineare allora $f(\lambda_{1}v_{1} + \lambda_{2}v_{2}) = f(\lambda_{1}v_{1}) + f(\lambda_{2}v_{2}) = \lambda_{1}f(v_{1}) + \lambda_{2}f(v_{2})$; viceversa se $f(\lambda_{1}v_{1} + \lambda_{2}v_{2}) = \lambda_{1}f(v_{1}) + \lambda_{2}f(v_{2}) \ \ \ \forall v_{1}, v_{2} \in V, \ \ \ \forall \lambda_{1}, \lambda_{2} \in \mathbb{R}$ allora $f$ è lineare
			- ovviamente si generalizza per $\lambda_{1}v_{1} + \cdots + \lambda_{n}v_{n}$
	- esempio migliore di nucleo
		- sia $f: \mathbb{R}^{3} \to \mathbb{R}^{2}$, $(x_{1}, x_{2}, x_{3}) \to (x_{1}+x_{2}, x_{1}-x_{3})$ applicazione lineare; trovare $\ker(f)$ e dire se $f$ è iniettiva
			- dalla definizione di kernel si ha che $\ker(f) = \{(x_{1}, x_{2}, x_{3}) \in \mathbb{R}^{3} | (x_{1}+x_{2}, x_{1}-x_{3}) = (0, 0)\}$
			- per cui $\ker(f)$ è l'insieme delle soluzioni del sistema lineare omogeneo $$\begin{cases} x_{1}+x_{2} = 0 \\ x_{1}-x_{3} = 0 \end{cases}$$
			- ovvero $x_{2} = -x_{1}, x_{3} = x_{1}$, per cui $\ker(f) = \{(x_{1}, -x_{1}, x_{1}) | x_{1} \in \mathbb{R}\} = \{x_{1}(1, -1, 1) | x_{1} \in \mathbb{R}\} = \langle (1, -1, 1) \rangle$
				- nota bene: il sistema è omogeneo, per cui ha sempre soluzione nulla, infatti nel nucleo c'è sempre l'insieme nullo perchè infatti $f(\underline{0}) = \underline{0}$
			- perciò visto che $\ker(f) = \langle (1, -1, 1) \rangle$, allora $\ker(f) \neq \{\underline{0}\}$, per cui _$f$ non è iniettiva_
	- proposizione importantissima, astratta
		- $V, W$ spazi vettoriali, $\beta = \{v_{1}, \cdots, v_{n}\}$ una base di $V$ e $w_{1}, \cdots, w_{n} \in W$ (non necessariamente distinti), allora si ha che **esiste una unica applicazione lineare a $f: V \to W | f(v_{1}) = w_{1}, \cdots, f(v_{n}) = w_{n}$**
		- dimostrazione: sia $v \in V$, definisco $f(v)$; abbiamo che $v = \lambda_{1}v_{1} + \cdots + \lambda_{n}v_{n}$ (perché $\beta$ è base), in particolare $(v)_{\beta} = (\lambda_{1}, \cdots, \lambda_{n})$; allora pongo $f(v) = \lambda_{1}w_{1} + \cdots + \lambda_{n}w_{n} \in W$, per cui ad ogni vettore $v$ associa un vettore di $w$; mostriamo allora che $f$ è lineare; siano $u, v \in V$ e mostriamo allora che $f(u + v) = f(u) + f(v)$; per cui intanto $u+v = \lambda_{1}v_{1} + \cdots + \lambda_{n}v_{n} + \beta_{1}v_{1} + \cdots + \beta_{n}v_{n} = (\lambda_{1} + \beta_{1})v_{1} + \cdots + (\lambda_{n} + \beta_{n})v_{n}$; allora $f(u+v) = (\lambda_{1} + \beta_{1})w_{1} + \cdots + (\lambda_{n} + \beta_{n})w_{n} = \lambda_{1}w_{1} + \cdots + \lambda_{n}w_{n} + \beta_{1}w_{1} + \cdots + \beta_{n}w_{n} = f(u) + f(v)$; ora il prodotto per scalari, per cui $f(\lambda v) = \lambda f(v) \ \ \ \forall \lambda \in \mathbb{R}$; allora $f(\lambda v) = \lambda\beta_{1}w_{1} + \cdots + \lambda\beta_{n}w_{n} = \lambda f(v)$; manca da dimostrare che $f$ è unica; sia $g: V \to W$ lineare tale che $g(v_{1}) = w_{1}, \cdots, g(v_{n})=w_{n}$, allora sia $v \in V$, ho che $g(v) = g(\lambda_{1}v_{1} + \cdots + \lambda_{n}v_{n}) = \lambda_{1}g(v_{1}) + \cdots + \lambda_{n}g(v_{n}) = \lambda_{1}w_{1} + \cdots + \lambda_{n}w_{n} = f(v)$ (per la linearità di $g$), per cui $g(v) = f(v)$, ergo è unica
		- conseguenza: se ho $f: V \to W$ lineare e $\beta = \{v_{1}, \cdots, v_{n}\}$ base di $V$, ho che se conosco $f(v_{1}), \cdots, f(v_{n})$ conosco anche $f$[^1]
		- esempio: sia $f: \mathbb{R}^{3} \to \mathbb{R}^{2}, (x_{1}, x_{2}, x_{3}) \to (x_{1}+x_{2}, x_{1}-x_{3})$
			- $f(1, 0, 0) = (1, 1)$
			- $f(0, 1, 0) = (1, 0)$
			- $f(0, 0, 1) = (0, -1)$
			- ora sia $A = \begin{pmatrix} 1 & 1 & 0 \\ 1 & 0 & -1 \end{pmatrix}$, le colonne sono le immagini di $f$ sulla base canonica di $\mathbb{R}^{3}$
				- consideriamo $L_{A}: \mathbb{R}^{3} \to \mathbb{R}^{2}$ solita, che mappa $\underline{x}$ in $A \underline{x}$
				- allora per il teorema di prima ho $f = L_{A}$
				- il teorema ci dice infatti che tutte le applicazioni lineari sono del tipo $L_{A}$
					- infatti se faccio $\begin{pmatrix} 1 & 1 & 0 \\ 1 & 0 & -1 \end{pmatrix} \cdot \begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \end{pmatrix} = \begin{pmatrix} x_{1}+x_{2} \\ x_{1}-x_{3} \end{pmatrix}$
			- morale: se $f: \mathbb{R}^{n} \to \mathbb{R}^{m}$ è un'applicazione lineare lineare, allora $f = L_{A}$
		- nota bene: stiamo usando pesantemente la base canonica
		- esempio: $f: \mathbb{R}^{5} \to \mathbb{R}^{3}$
			- fondamentalmente, trovata $A$ posso chiedere "chi è $f(x_{1}, x_{2}, x_{3}, x_{4}, x_{5})$?" e rispondere $A \cdot \begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \\ x_{4} \\ x_{5} \end{pmatrix}$
			- per cui il nucleo è $\{\underline{x} | L_{A}(\underline{0}) = \underline{0}\}$, per cui $\{\underline{x} | A \underline{x} = \underline{0}\}$
				- nota: le soluzioni di un sistema lineare omogeneo sono il nucleo

## Domande

## Referenze
[^1]: grande differenza con l'analisi, per la quale non è possibile, sapendo 3 punti dell'immagine di una funzione, conoscere la funzione stessa