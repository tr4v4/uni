---
tags:
  - category/lecture
  - status/finished
  - topic/linguaggi-di-programmazione
date: 15-10-2024 11:03:02
teacher: roberto.gorrieri@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- minimizzazione DFA - continuo
	- ripasso algoritmo a scala
	- ora facciamo tutti gli step che portano da un'espressione regolare a creare un DFA minimo
		1. definiamo un'espressione regolare $a^{*} \epsilon b^{*}$
		2. costruiamo l'NFA associato (esagerando tantissimo con numero di stati e transizioni-$\epsilon$)
		3. ricaviamo il DFA equivalente con la costruzione per sottoinsiemi
		4. minimizziamo il DFA
		5. ricaviamo la grammatica regolare dal DFA
		6. semplifichiamo le grammatiche, rimuovendo i simboli inutili
		7. estraiamo dalla grammatica l'espressione regolare associata
	- di solito si ottiene un'espressione regolare in output diversa da quella in input, ma si dimostra che sono equivalenti
	- si dimostra che il diagramma delle "equivalenze regolari" commuta
	- definizione formale di automa minimo: dato un DFA $M = (\Sigma, Q, \delta, q_{0}, F)$, l'automa minimo equivalente $M_{\min} = (\Sigma, Q_{\min}, \delta_{\min}, [q_{0}], F_{\min})$ dove
		- $Q_{\min} = \{[q] | q \in Q\}$ dove $[q] = \{q' \in Q | q \sim q'\}$, ossia è l'insieme delle classi di equivalenza della relazione $\sim$
		- $\delta_{\min}([q], a) = [\delta(q, a)]$
		- $F_{\min} = \{[q] | q \in F\}$
	- osservazione: non esistono 2 stati distinti in $M_{\min}$ che siano tra loro equivalenti, ossia $[q] \neq [q'] \implies q \nsim q'$
	- dimostriamo che l'automa definito così è effettivamente il più piccolo e che è equivalente al DFA di partenza
		- notazione:
			- per un DFA vale
				- $\hat{\delta}: Q \times \Sigma^{*} \to Q$, è la funzione che presa uno stato e una stringa restituisce l'unico stato che possono raggiungere con il DFA leggendo quella stringa e partendo da quello stato
				- $\hat{\delta}(q, \epsilon) = q$
				- $\hat{\delta}(q, xa) = \delta(\hat{\delta}(q, x), a)$
				- quindi $w \in L[M] \iff \hat{\delta}(q_{0}, w) \in F$
			- per un DFA minimo, equivalente ma con notazione più pesante perché si usano classi di equivalenza
		- teorema: dato un DFA $M = (\Sigma, Q, \delta, q_{0}, F)$, l'automa $M_{\min} = (\Sigma, Q_{\min}, \delta_{\min}, [q_{0}], F_{\min})$ riconosce lo stesso linguaggio di $M$ ed ha il minimo numero di stati tra tutti gli automi deterministici
		- dimostrazione:
			1. $M_{\min}$ è ben definito, cioé la definizione di $\delta_{\min}$ non dipende dallo specifico stato scelto per rappresentare la classe di equivalenza, ossia se $[q] = [q']$, allora $\delta_{\min}([q], a) = \delta_{\min}([q'], a)$ --> in breve non importa quale rappresentante scelgo per le classi di equivalenza
			2. per dimostrare che $L[M] = L[M_{\min}]$ dimostro che $\hat{\delta}(q_{0}, w) = r \iff \hat{\delta}_{min}([q_{0}], w) = [r]$, ovvero che $\hat{\delta}_{min}([q_{0}], w) = [\hat{\delta}(q_{0}, w)]$, per induzione
				- base: $|w| = 0$, cioé $w = \epsilon$, si dimostra facilmente
				- induttivo: $w = xa$
			3. rimane da dimostrare che è minimo, lo dimostriamo per assurdo supponendo che esista un automa deterministico con un numero minore di stati di quello minimo e che sia equivalente a quello minimo
				- osserviamo che gli stati iniziali devono essere equivalenti
				- osserviamo che se vale l'osservazione precedente devono essere equivalenti anche quelli successori
				- osservazione 3
				- osservazione 4
- **lex** - generatore di scanner
	- è un software, che gira sotto Unix, scritto da Mike Lesk e Eric Schmidt
	- FLEX è la versione più recente e aggiornata di Lex, free
	- Lex/FLEX generano analizzatori lessicali (scanner)
	- in input prendono un file di tipo `.l`  che contengono un insieme di definizioni regolari e una serie di azioni corrispondenti
	- in output forniscono un programma [[C]] che realizza l'automa riconoscitore e che associa ad ogni istanza di una definizione la relativa azione
	- workflow di lavoro
	- file di input `lex.l`
		- diviso in 3 parti:
			1. _dichiarazioni_, espressioni regolari delle categorie sintattiche
			2. _regole_, associazioni tra espressioni regolari (pattern) e azioni (scritte in C); le azioni sono per esempio la stampa del token, quindi associazione tra pattern e lessema
			3. _funzioni ausiliarie_, da definire se si usano funzioni complesse nella parte "azione"
	- come funziona `lex.yy.c`, ossia lo scanner generato e restituito da lex in output
		- in parole povere è il DFA che riconosce tutti i pattern (solo uno!)
		- in particolare:
			- scandisce il testo sorgente alla ricerca di lessemi di 
	- esempio banale
		- da notare bene il fatto che alcuni pattern possono essere prefissi di altri o casi speciali di altri:
			- il sistema cerca sempre il lessema del pattern più lungo
			- il sistema riconosce sempre il primo pattern in elenco (nel caso di casi speciali)
		- per farlo crea dei singoli NFA per ogni pattern; quindi li unisce e fa una simulazione DFA dell'NFA, costruendosi una tabella che contiene per ogni stato del DFA (sottoinsiemi di stati dell'NFA) i pattern riconosciuti e le azioni corrispondenti leggendo i simboli in input
	- esempio più interessante
	- in realtà l'analisi lessicale viene fatta in parallelo con l'analisi sintattica
		- diagramma da immagine
		- l'analizzatore sintattico è prodotto in modo semi-automatico da **YACC**
		- diciamo quindi che lex è una subroutine di yacc
		- quindi `lex.yy.c` è usato "on demand" da yacc, che richiede il token successivo di volta in volta
	- quindi guardiamo la struttura del file `.l` per poter essere usata da yacc
		- si utilizza `yylval`, una variabile condivisa tra lex e yacc
- proprietà algoritmiche dei linguaggi regolari
	- non abbiamo dimostrato che esistono linguaggi liberi non regolari, mentre sappiamo che tutti i linguaggi regolari sono liberi
	- vediamo una proprietà algoritmica dei linguaggi regolari che ci è utile per dimostrare che certi linguaggi senza quella proprietà non sono regolari
	- esempi
		- $L = \{a^{n}b^{n} | n \geq 0\}$ è libero ma non regolare
			- intuitivamente bisognerebbe avere infiniti stati dell'automa associato al linguaggio regolare equivalente
		- $L = \{a^{n}b^{m} | n, m \geq 0\}$ è regolare
	- teorema: **pumping lemma**
		- se $L$ è un linguaggio regolare, allora $\exists N > 0$ tale che $\forall z \in L$ con $|z| \geq N, \ \ \exists u, v, w$ tali che
			- $z = uvw$
			- $|uv| \leq N$
			- $|v| \geq 1$
			- $\forall k \geq 0 \ \ \ uv^{k}w \in L$
		- inoltre $N$ è minore o uguale del numero di stati del DFA minimo che accetta $L$
		- dimostrazione (chiesta spessa all'orale):
			- sia $N = |Q_{M}|$ dove $M$ è il DFA minimo che accetta $L$; sia $z = a_{1}a_{2}\cdots a_{m}\in L$ con $m \geq N$;
			- quindi partendo dallo stato $q_{0}$ leggo ogni carattere fino ad arrivare a $q_{m} \in F$;
			- ora $0-m$ è dato da $m+1$ stati con $m+1 > N$ $\implies \exists i, j (i \neq j) : q_{i} = q_{j}$[^1]
			- poiché $i \neq j$, allora $v = a_{i+1} \cdots a_{j}$ è tale che $|v| \geq 1$
			- la condizione $|uv| \leq N$ mi dice che prendo il primo ciclo
			- la 4° considerazione è ovvia perché posso ciclare $v$ per $k$ volte e farà sempre parte del linguaggio
		- osservazione: se $L$ è finito allora non c'è alcuna $z \in L$ con $|z| \geq N$, per cui l'implicazione è vera perché la premessa è falsa
		- altra osservazione:
	- usiamo il pumping lemma con la contronomiale!
		- quindi per riconoscere se un linguaggio non è regolare ci basta dimostrare che non vale il pumping lemma
		- devo negare tutto il pumping lemma, che viene così:
			- se $\forall N > 0 \ \ \exists z \in L \ \ |z| \geq N \ \ \ \forall uvw \ \ z = uvw, |uv| \leq N, |v| \geq 1 \implies \exists K \geq 0. uv^{k}w \notin L$, allora $L$ non è regolare

## Domande

## Referenze
[^1]: gran paragone con i cicli dei grafi