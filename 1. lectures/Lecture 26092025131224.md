---
tags:
  - category/lecture
  - status/finished
  - topic/introduzione-all-apprendimento-automatico
date: 26-09-2025 13:12:24
teacher: andrea.asperti@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- **albero di decisione**
	- il framework è quello di _approssimazione di funzioni_, richiediamo un dataset supervisionato
	- abbiamo infatti il training set composto da coppie (input, output)
		- $(x^{(i)}, y^{(i)})$
	- $Y$ (l'insieme di output) può essere
		- _discreto_ - problema di classificazione
		- _continuo_ - problema di regressione
	- gli alberi di decisione possono lavorare sia su features discrete che continue
	- bisogna scegliere lo _spazio delle ipotesi_: l'insieme delle funzioni $H$ in cui ci aspettiamo di trovare il risultato
		- la soluzione potrebbe non appartenere ad $H$
		- ci accontentiamo della migliore rappresentazione possibile
	- dobbiamo anche avere un modo concreto per calcolare la funzione -> il modello!
		- quindi per ogni funzione dovremmo avere un modello
		- ma:
			- il modello è sufficientemente espressivo da poter rappresentare ogni funzione $h$ nello spazio delle ipotesi?
			- il modello è unico?
			- se non lo è, abbiamo una preferenza?
		- esempio $H: Outlook \times Humidity \times Wind \times Tempo \to Play Tennis?$
	- definizione: è un albero che ha associato ad ogni nodo una feature, e i figli sono altri nodi (in tal caso gli archi sono etichettati come i possibili valori assunti dalla feature genitore) o delle foglie (label, ossia l'output della funzione)
		- ci dobbiamo chiedere come costruire il modello (in questo caso l'albero) a partire dai dati
		- espressività degli alberi di decisione
			- riesco a rappresentare tutti i connettivi booleani $\implies$ sono tanto espressivi quanto tutte le feature discrete
	- questi modelli non generalizzano assolutamente --> fanno overfit totale
		- una volta che è stato costruito l'albero, con nuovi dati è difficile che sia in grado di generalizzare
	- questioni importanti:
		- un unico albero di decisione per ogni funzione $h$ nello spazio delle ipotesi? No, basta riordinare le features
		- la profondità massima è limitata dal numero di features
			- l'albero "migliore" magari è quello che ha profondità minima
			- vogliamo creare quindi _alberi bilanciati_, e quindi cercare features che bilancino il più possibile l'albero
	- costruzione
		- approccio top-down
			- dalla radice arrivo alle foglie
			- loop:
				- assegno al nodo corrente il "miglior" attributo $X_{i}$;
				- creo un nodo figlio per ogni possibile valore di $X_{i}$ e propago i dati verso i figli a seconda del loro valore;
				- per ogni nodo figlio, se tutti i dati del training set associato al nodo hanno una stessa etichetta $y$, marco il nodo come foglia con etichetta $y$, altrimenti ripeto dal primo punto
			- nota bene: posso non arrivare alle foglie, ossia costruire l'albero non completo --> in tal caso interpreto il risultato come una probabilità!
			- il problema interessante è quello di capire _qual è il "miglior" attributo (feature)_
	- ricerca della miglior feature
		- l'idea è di cercare di bilanciare l'albero il più possibile, e di avere invece il massimo sbilanciamento nella separazione dei nipoti, in modo che se si interrompe la computazione dell'albero a quel livello ho una probabilità diversa dal 50%
		- _entropia_
			- l'entropia $H(X)$ di una [[Variabile aleatoria|variabile aleatoria]] discreta $X$ è $$H(X) = -\sum\limits_{i=1}^{n} \mathbb{P}(X = i) \log_{2}{(\mathbb{P}(X = i))}$$
				- è una somma pesata di $\log_{2}(\mathbb{P}(X = i))$, che è la _funzione di informazione_
			- misura il grado di disordine/impurità dell'informazione
			- è massima, ossia $\log{n}$, quando $X$ è uniformemente distribuita tra tutti i suoi $n$ valori, e minima, ossia $0$, quando è concentrata su un singolo valore
			- caso particolare per $\mathbb{P}(X = 0)$ nel caso in cui l'entropia sia minima (probabilità concentrata in 1 punto)
			- ![[entropia-grafico-1.png]]
				- nel caso di supporto $S_{X} = \{0, 1\}$
		- _teoria dell'informazione_ - Shannon
			- l'entropia è la quantità media di informazione prodotta da una sorgente stocastica di dati
				- quindi l'informazione è associata alla probabilità di ogni dato (la "sorpresa" associata all'evento)
					- un evento con probabilità 1 non trasmette informazione -> $I(1) = 0$
					- dati due eventi indipendenti con probabilità $p_{1}, p_{2}$, la probabilità congiunta è $p_{1} \cdot p_{2}$ ma l'informazione acquisita è la somma delle informazioni dei due eventi indipendenti -> $I(p_{1} \cdot p_{2}) = I(p_{1}) + I(p_{2})$
					- ci aspettiamo che l'informazione sia antimonotona rispetto alla probabilità, ed è quindi naturale definire l'informazione come un logaritmo: $$I(p) = -\log(p)$$
			- l'entropia misura il numero medio di bits richiesti per trasmettere il valore prodotto da una sorgente stocastica $X$
				- se per esempio abbiamo $n$ eventi con la stessa probabilità, allora servono $\log(n)$ bits per codificare ogni possibile risultato
				- l'entropia $H(X)$ è proprio uguale a $\log(n)$
				- se invece gli eventi non hanno la stessa probabilità possiamo migliorare la codifica!
			- _guadagno informatico_
				- entropia
				- entropia condizionale di $X$ dato uno specifico $Y = v$
				- entropia condizionale di $X$ dato $Y$
				- guadagno informatico tra $X$ e $Y$
					- $I(X, Y) = H(X) - H(X|Y)$
			- si vuole trovare l'albero che massimizza il guadagno informativo e che osservandolo si minimizza l'entropia della distribuzione
				- l'obiettivo è massimizzare il guadagno dell'informazione
			- questo si fa nel caso in cui chiaramente non si scandisce tutto l'albero, ma in cui rimangono dei casi aperti --> per predire! in tal caso vogliamo l'entropia minima alle foglie
	- caso continuo
		- se le features sono continue andiamo a discretizzarle con una soglia (threshold)
		- il problema diventa come scegliere le soglie!
			- potrei guardare il dataset, che è comunque finito, e uso i valori assunti dalla feature come intervallo entro cui stabilire le soglie

## Domande
- eeeeehhh

## Referenze
