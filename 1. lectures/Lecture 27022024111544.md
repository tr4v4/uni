---
tags:
  - category/lecture
  - status/finished
  - topic/algoritmi-e-strutture-dati
date: 27-02-2024 11:15:44
teacher: pietro.dilena@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- concludiamo analisi della complessità degli algoritmi
- dobbiamo discutere tecniche per analizzare la complessità compiutazionale di algoritmi ricorsivi --> risolviamo equazioni di ricorrenza
- tecniche
	- **metodo dell'iterazione**
	- **master theorem**
	- metodo della sostituzione (non lo faremo)
	- metodo dell'albero di ricorsione (non lo faremo)
- ci sono alcune situazioni in cui non è comunque possibile risolvere le equazioni di ricorrenza...
- equazioni di ricorrenza
	- sono associate a un algoritmo ricorsivo, ed espresse in notazione asintotica
	- $$T(n) = \begin{cases} \Theta(1) & n=1 \\ 2T\left(\frac{n}{3}\right)+ O(n) & n > 1 \end{cases}$$
	- possiamo sostituire le notazioni asintotiche con _espressioni positive_
	- $$T(n) = \begin{cases} d & n=1 \\ 2T\left(\frac{n}{3}\right)+ cn & n > 1 \end{cases}$$
	- sostituiamo ora tutte le costanti con $1$ (alla fine non ci importa né di $d$ né di $c$ preciso, perché analizziamo il comportamento asintotico)
	- $$T(n) = \begin{cases} 1 & n=1 \\ 2T\left(\frac{n}{3}\right)+ n & n > 1 \end{cases}$$
	- il comportamento asintotico non è influenzato da arrotondamenti, quindi togliamo la funzione _floor_
	- $$T(n) = \begin{cases} 1 & n=1 \\ 2T\left(\frac{n}{3}\right)+ n & n > 1 \end{cases}$$
- metodi
	- **metodo dell'iterazione**
		- è un approccio _brute force_, in cui _sostituiamo iterativamente la parte ricorsiva nell'equazione finché non appare uno schema ricorsivo legato al passo di iterazione_
		- lo avevamo già usato nel calcolo del numero di nodi nell'albero di Fibonacci
		- prendiamo ad esempio
			- $$T(n) = \begin{cases} 1 & n = 1 \\ T\left(\frac{n}{2}\right)+ 1 & n > 1 \end{cases}$$
			- $T(n) = T\left(\frac{n}{2}\right)+ 1 = T\left(\frac{n}{4}\right) + 1 + 1 = T\left(\frac{n}{8}\right) + 1 + 1 + 1 = \cdots = T\left(\frac{n}{2^{i}}\right) + i$
			- la ricorsione termina quando $\frac{n}{2^{i}} = 1 \implies i = \log_{2}(n)$
			- al caso base, allora, avremo $T(n) = T(1) + \log_{2}(n) = 1 + \log_{2}(n) = \Theta(\log{n})$
		- fare sempre riferimento alle formule chiuse note per semplificare le sommatorie
	- **master theorem**
		- è un teorema che ci permette di _risolvere istantaneamente tutte le equazioni di ricorrenza che hanno la seguente forma_
			- $$T(n) = aT\left(\frac{n}{b}\right)+ f(n)$$
			- con $a \geq 1$, $b \geq 1$ _costanti_ e $f(n)$ _asintoticamente positiva_ ([[Funzione di costo|funzione di costo]])
		- 3 casi, che confrontano il rate di crescita di $f(n)$, in generale, con $n^{\log_{b}(a)}$
			- difficilissimi
		- useremo la _versione semplificata_, meno generale, che analizza solo equazioni di ricorrenza del tipo
			- $$T(n) = \begin{cases} d & n = 1 \\ T\left(\frac{n}{2}\right) + cn^{\beta} & n > 1 \end{cases}$$
			- quindi fissiamo $\alpha = \log_{b}(a)$, e
				- $\alpha > \beta \implies T(n) = \Theta(n^{\alpha})$
				- $\alpha = \beta \implies T(n) = \Theta(n^{\alpha}\log{n})$
				- $\alpha < \beta \implies T(n) = \Theta(n^{\beta})$
			- velocissimo
		- esempio di utilizzo per algoritmo di ricerca binaria ricorsivo
			- _caso ottimo_: $O(1)$
			- _caso pessimo_: analizziamo l'equazione ricorrenza
				- $$T(n) = \begin{cases} 1 & n = 0 \\ T\left(\frac{n}{2}\right) + 1 & n > 0 \end{cases}$$
				- $\alpha = \log_{2}{1} = 0$, $\beta = 0$, quindi
				- $$T(n) = \Theta(\log{n})$$
	- concludiamo con il trovare il $\Theta$ dell'algoritmo per il calcolo di nodi nell'albero di Fibonacci
		- non possiamo usare il Master Theorem, ed è durissima farlo con il metodo dell'iterazione --> problema ostico
		- usiamo un teorema
			- Sia $T(n)$ l'equazione di ricorrenza di Fibonacci. Allora $T(n) = 2F_{n} - 1$
			- si dimostra per induzione
		- allora sappiamo che $T(n) = \Theta(2F_{n} - 1) = \Theta(F_{n})$
		- dalla formula sappiamo che l'$n$-esimo numero di Fibonacci è definito da $F_{n} = \frac{1}{\sqrt{5}} (\phi^{n} - \hat{\phi}^{n})$
		- concludiamo allora che $T(n) = \Theta(\phi^{n})$
			- ci eravamo andati vicini perché il lower-bound era $\Omega(\sqrt{2}^{n})$, mentre l'upper-bound era $O(2^{n})$
- esercizi su equazioni di ricorrenza
	- proviamo a calcolare la complessità compiutazionale dell'algoritmo di Fibonacci, otteniamo la stessa equazione di ricorrenza di Fibonacci --> per il Master Theorem abbiamo $\Theta(\log{n})$
		- interessante: rifacendo l'algoritmo ma con l'_exponentiation by cubing_, il rate asintotico è sempre lo stesso! $\Theta(\log{n})$
	- esempi da `Mistery1` e `Mistery2`
		- fare quelli da virtuale

## Domande

## Referenze
