---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-numerico
date: 11-11-2024 13:17:00
teacher: elena.loli@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- ripasso problemi inversi
	- li vedremo applicati alle immagini: _imaging_
- **imaging**
	- il processo di digitalizzazione consiste in una sorta di costruzione di un reticolo composto da quadratini (pixel) ognuno caratterizzato da un colore (anche se noi lavoreremo con immagini in bianco e nero)
	- quindi ogni immagine è memorizzata come un array bidimensionale (tabella), o matrice, in cui ogni cella ha per valore l'intensità della scala di grigi di quel pixel
	- consideriamo quindi ogni immagine come una matrice $M \times N$
	- definizione: sia $A$ una matrice $M \times N$ e sia $K \in \mathbb{N}$, diremo che una matrice $B$ di dimensioni $(M + 2k) \times (N + 2k)$ **estende** la matrice $A$ $\iff$ vale la relazione $$\forall (i, j) \in \{1, \cdots, M\} \times \{1, \cdots, N\}. \ \ \ A_{(i,j)} = B_{(i+k, j+k)}$$
		- esempio per capire bene
		- la matrice $A$ è al centro della sua estesa $B$
			- quindi aggiungo gli elementi in un certo modo: in modo tale da far rimanere $A$ "al centro"
	- nota bene: ogni matrice ha infinite estensioni!
	- definizione: sia $K$ una matrice $D \times D$ con $D$ dispari, allora si definisce **centro** di $K$ l'elemento di coordinate $(\frac{D+1}{2}, \frac{D+1}{2})$
	- definiamo $W_{(i,j)}$
	- **convoluzione**:
		- sia $A$ una matrice $M \times N$, $K$ una matrice chiamata kernel di dimensioni $D \times D$ con $D$ dispari, definiamo $C$ una matrice $M \times N$ composta come $$C_{(i, j)} = \sum\limits_{m=1}^{\frac{D-1}{2}} \sum\limits_{n=1}^{\frac{D-1}{2}} K(m,n) W_{(i,j)}(m,n)$$
		- e si dice che $C = [K * A | B]$, ossia la convoluzione di $K$ e $A$ rispetto all'estensione $B$
			- la $B$ è necessaria, infatti l'estensione di $A$ ci consente di lavorare sui bordi di $A$
		- il risultato quindi è $C$, che ha le stesse dimensioni di $A$, ma sarà diversa da $A$: è il risultato della convoluzione di $A|B$ ($A$ estesa $B$) per il kernel
	- dobbiamo capire intanto come estendere $A$: non possiamo farlo a caso!
		- 3 modalità principali, chiamate **condizioni al bordo**:
			- _estendo $A$ con bordo nero_, si fa di solito quando l'immagine ha sfondo nero, così da non creare discontinuità
			- _estendendo $A$ a periodico_, ripetendo l'immagine in alto, in basso, a destra e a sinistra
			- _estendendo $A$ a specchio_, ripetendo gli ultimi pixel al contrario, in alto, in basso, a destra e a sinistra
	- definizione formale di condizioni riflessive;
	- definizione formale di convoluzione;
	- _differenze di risultati a seconda dei kernel_ --> filtri!
	- **PSF** - l'azione dello strumento di cattura delle immagini produce sempre una distorsione dell'oggetto catturato
		- può derivare dal movimento relativo, da errori di misura, ecc...
		- la funzione $\mathcal{A}$ che realizza questa distorsione si chiama **Point Spread Function** (PSF), ed è modellizzabile come una convoluzione per un determinato kernel
		- supponiamo che questo allargamento, distorsione/sfocatura, non dipenda dalla posizione della fonte, e che quindi il kernel sia uguale per tutti i punti dell'immagine
			- si dice che PSF è _spazio invariante_
		- formalmente allora si ha che se $x$ è l'immagine originale, allora la funzione $\mathcal{A}(x)$ è modellizzabile come $$\mathcal{A}(x) = [K * x | \mathcal{P}]$$
			- dove $K$ è un qualche kernel, e $\mathcal{P}$ è un pattern di estensione (condizione al bordo)
		- la PSF è una _distorsione deterministica_
	- **rumore bianco**
		- ci sono anche fenomeni aleatori e non prevedibili che contribuiscono a danneggiare l'immagine acquisita
		- in particolare la digitalizzazione introduce questo tipo di rumore: _rumore Gaussiano bianco_
		- possiamo modellizzare anche questo come l'aggiunta di una matrice $w$ ottenuta attraverso il sampling di una funzione random (con caratteristiche particolari): $$y^{\delta} = \mathcal{A}(x) + w = [K * x | \mathcal{P}] + w$$
	- allora il processo di acquisizione e digitalizzazione è modellizzabile come una sequenza di processi (immagina da inserire)
	- obiettivo: _data l'immagine osservata $y^{\delta}$ e nota la PSF ($K$), si vuole ripulire l'immagine per riottenere l'oggetto acquisito_
		- posso anche scrivere il modello come $$y^{\delta} = Ax + w$$ dove $$Ax = K * x$$
		- ma questa è esattamente la forma dei problemi inversi!
		- naive:
			- posso risolvere il problema di minimi quadrati $$\min_{x} {\|Ax - y^{\delta}\|_{2}}^{2}$$
			- il risultato fa schifo, perché è dominato dal rumore
			- attenzione: la risolvo usando un metodo iterativo, e non diretto --> CGLS, perché la SVD sarebbe troppo costosa computazionalmente!
				- in particolare, supponendo che $A$ abbia rango massimo (abbastanza realistico considerando che si tratta di immagini), applico le equazioni normali
				- quindi risolvo $A^{T}Ax = A^{T}y^{\delta}$
				- ma attenzione: $x$ e $y^{\delta}$ sono immagini, quindi matrici --> le dobbiamo trasformare in vettori --> **riordinamento lessicografico**
					- può essere fatto per righe o per colonne
					- quindi $x$ matrice $M \times N$ --> vettore $M \times N$ componenti
					- in Python: `np.reshape`
				- si usano metodi iterativi, come i gradienti coniugati
		- metriche per la valutazione:
			- da usare nei problemi test, per valutare le performance degli algoritmi risolutivi
			- metriche:
				- _ER_ --> errore relativo
				- _PSNR_ --> misura del rumore, valori in $[0, 100]$, più è alto migliore è l'immagine
					- usa il _MSE_
				- _SSIM_ --> indice più fedele alla qualità visiva dell'immagine, valori in $[0, 1]$, più è alto migliore è l'immagine

## Domande

## Referenze
