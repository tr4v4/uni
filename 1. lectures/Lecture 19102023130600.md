---
tags:
  - category/lecture
  - status/finished
  - topic/architettura-degli-elaboratori
date: 19-10-2023 13:06:00
teacher: ivan.lanese@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- cache
	- è invisibile anche ad Assembly
- paginazione
	- a volta la RAM è troppo piccola --> si usa il disco rigido come se fosse RAM: **memoria virtuale**
	- quindi anche da disco a RAM bisogna decidere quali dati portare: stessa questione tra cache e RAM
		- diversa gerarchia di memoria
		- diverse velocità e capacità
		- un miss in memoria virtuale pesa di più di un miss in cache
	- algoritmi di paginazione (eseguiti dal [[SO]]) per gestire scambio di dati tra disco fisso e RAM
- pre-fetch istruzioni / pipelining
	- se eseguo l'istruzione 85, la successiva molto probabilmente sarà l'86 (ad eccezione di _salti_...)
	- quindi mentre eseguo l'85 carico già l'86: ho una buona probabilità di prenderci
	- ci serve quindi un pezzo di CPU che mentre viene fatto Decode-Execute dell'istruzione corrente carica in Fetch quella successiva: **Instruction Fetch Unit** per fare _pre-fetch_
		- questo potrebbe ridurre la durata del ciclo di clock (perché Execute e Fetch vengono fatte contemporaneamente)
	- a questo punto si può fare di meglio: **pipelining**
		- esempio di stadi
			1. fetch
			2. decode
			3. caricamento operandi
			4. esecuzione
			5. scrittura dei risultati
		- allora faccio un ciclo di clock per ogni stadio (prima facevo 1 ciclo di clock per operazione), sembra svantaggioso ma in realtà si finisce con fare con meno cicli di clock più operazioni --> il ciclo di clock dura meno
		- supponendo che ogni stadio occupi 1 microsecondo
			- il clock di HACK durerebbe 5 microsecondi (deve farli in sequenza)
			- il clock di un processore con pipeline durerebbe 1 microsecondo (li fa contemporaneamente)
		- nella realtà abbiamo problematiche
			- in caso di `JMP` devo evitare che nel mentre che viene decodificato si interrompa il ciclo di fetch-decode-execute dell'esecuzione successiva (non deve eseguirsi!)
				- subito dopo il decode "butti via" il fetch dell'istruzione seguente e mentre si caricano gli operandi del `JMP` si fa il fetch dell'istruzione giusta --> _si perde 1 ciclo di clock, traslando di una posizione ogni stadio_
				- ogni salto fa perdere 1 ciclo di clock
				- ovviamente, se abbiamo un `JMP` con eventuali operandi o addirittura somme il numeri di perdite dei clock aumenta
					- se `JMP X` si perdono 2 cicli di clock
					- se `JMP X+4` si perdono 3 cicli di clock
				- figuriamoci con i _salti condizionati_:
					- mentre si esegue la verifica della condizione si carica l'istruzione successiva e poi una volta capito se salto o non salto mi adatto
					- altrimenti --> **euristica**
						- di solito i salti indietro sono più frequenti dei salti in avanti (ci sono più cicli che `if`)
						- ci si basa fondamentalmente sulle probabilità
						- dalla decodifica già riusciamo a capire se sarà un salto in avanti o in indietro
							- ci si basa anche sulle ultime cose che son successe --> se si è saltato in passato spesso in indietro allora molto probabilmente sarà così anche questa volta
			- altro problema con le modifiche dei dati
				- se un'istruzione usa un dato modificato da quella precedente allora il dato non viene aggiornato
				- anche in questo caso si deve aspettare che l'istruzione che modifica i dati abbia finito tutti gli stadi prima che quella successiva possa caricare gli operandi
				- trucchetto! il compilatore compila l'assembly in modo tale da scambiare di posto le istruzioni dipendenti le une dalle altre
- microarchitettura in generale
	- microarchitettura di Intel Core i7
		- faccio operazioni nell'ordine più "comodo" per l'architettura della CPU (per sfruttare al medio l'hardware che ho)
		- poi riordino i risultati per avere il risultato corretto
		- composizione (blocchi più importanti)
- 

## Domande

## Referenze
