---
tags:
  - category/lecture
  - status/finished
  - topic/introduzione-all-apprendimento-automatico
date: 02-10-2025 13:16:19
teacher: andrea.asperti@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- **overfitting**
	- cerchiamo di risolvere un problema partendo da dei dati di training, ossia delle osservazioni prese rispetto al problema
		- ma le osservazioni sono limitate! Magari sono significative, magari no...
		- gli errori possono nascere dai sensori che catturano le osservazioni, o dal fatto che abbiamo scelto certi sensori che magari non influiscono sul problema
	- formalmente
		- prendiamo un'ipotesi (funzione) $h \in H$ ([[Spazio delle ipotesi]])
			- l'errore relativo sul training set è $error_{train}(h)$
			- l'errore relativo sull'intero data set $\mathcal{D}$ è $error_{\mathcal{D}}(h)$
		- diciamo che allora $h$ overfitta il training set se esiste un'altra ipotesi $h'$ tale che $$error_{train}(h) < error_{train}(h')$$ ma $$error_{\mathcal{D}}(h) > error_{\mathcal{D}}(h')$$
		- esempio con alberi di decisione
			- più aumenta la complessità, e quindi la profondità, dell'albero, più riesco a modellare bene il training set
			- ma si rende troppo complesso il modello, rischia di minimizzare l'errore sul training set, ma di fare poi schifo sul data set
			- ![[overfitting-e-complessità.png]]
			- chiaramente il caso simmetrico è l'underfitting, ossia in cui il modello è troppo semplice e non cattura sufficientemente il problema
		- il problema è che noi non conosciamo $\mathcal{D}$!
			- sono i dati veri del problema
			- allora usiamo una tecnica:
				- dividiamo i dati di training in 2 gruppi:
					- il vero _training set_
					- il _validation set_, utilizzato per misurare l'accuratezza e overfitting
						- nel caso degli alberi di decisione, capiamo quando vale la pena fermarsi nella costruzione dell'albero
					- in realtà di solito ci sono anche i dati di _test set_, per la valutazione finale
	- come evitiamo l'overfitting negli alberi di decisione?
		- **early stopping**
			- terminiamo la costruzione dell'albero non appena il miglioramento non è più statisticamente significativo migliorare il modello
			- per esempio quando il [[Guadagno informativo]] è sotto una certa soglia, o quando il numero dei dati relativo al nodo è troppo piccolo
		- **post-pruning**
			- costruiamo l'intero albero, finendo tutto il training set, e poi procediamo a potarlo all'indietro
			- tecnica
				- costruisco l'intero albero per il training set
				- ripeto l'operazione finché ogni ulteriore pruning non migliora l'accuratezza della predizione:
					- per ogni sottoalbero, valutare (nel validation set), l'impatto della sua rimozione sull'accuratezza della classificazione
					- effettuare (in modo [[Algoritmi greedy|greedy]]) il pruning del sottoalbero che ottimizza l'accuracy
			- infatti, _se migliora l'accuratezza dopo la potatura nel validation set, significa che l'albero era in overfitting nel training set_
	- in generale, per diminuire l'overfitting ci sono i seguenti modi:
		- il modo migliore è quello di aumentare il training set
			- questo si può fare usando anche _data augmentation_, è una cosa delicata
		- un altro modo è usando [[Regolarizzazione]]
		- altra tecnica è il drop-out
- aspetti positivi degli alberi di decisione
	- modello explainable
	- poco preprocessing
	- costo predittivo basso (ricerca nell'albero)
	- utilizzabile sia con features discrete che continue
- aspetti negativi degli alberi di decisione
	- rischio elevato di overfitting
	- selezione degli attributi instabile al variare del dataset
	- facile costruire alberi profondamente sbilanciati --> specialmente con classi dominanti
- gli alberi decisionali sono usati di solito all'interno di **Random Forests**
	- attraverso la tecnica ad _ensemble_
		- "se la maggioranza degli alberi dice $y$, allora è $y$"
		- questa tecnica si basa sul principio che un _gran numero di modelli sufficientemente scorrelati che operano come un comitato forniscono risultati migliori dei singoli componenti_
	- per garantire la differenziazione degli alberi si usa:
		- _bagging_ - allenare i modelli su sottoinsiemi random (bags) dei dati di input;
		- _feature randomness_ - costruire gli alberi a partire da sottoinsiemi random delle features;
- **approccio probabilistico**
	- idea di base
		- vogliamo approssimare una funzione $f: X \to Y$, e lo facciamo calcolando $p: \mathbb{P}(Y|X)$
	- ripasso di probabilità

## Domande
- si possono adattare gli alberi decisionali a una versione di reinforcement learning? Ossia che siano live, e si adattino ad ogni nuovo input e output?

## Referenze
