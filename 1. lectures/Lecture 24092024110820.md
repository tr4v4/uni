---
tags:
  - category/lecture
  - status/ongoing
  - topic/linguaggi-di-programmazione
date: 24-09-2024 11:08:20
teacher: roberto.gorrieri@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- continuo descrizione linguaggio di programmazione
	- rappresentazione finita dei linguaggi
		- se $L$ è infinito, come possiamo rappresentarlo? questo è il **problema centrale dell'informatica** --> abbiamo oggetti infiniti ma memoria finita
		- prendiamo spunto dall'assioma di Peano per rappresentare i numeri naturali per induzione con una semplice regola di inferenza
			- di fatto non possiamo memorizzare tutto $\mathbb{N}$, ma implicitamente possiamo definirlo come
				- $0 \in \mathbb{N}$
				- $x \in \mathbb{N} \implies S(x) \in \mathbb{N}$ (dove $S$ è il successore)
			- genero $\mathbb{N}$ quindi come $\mathbb{N} = \{0, S(0), S(S(0)), \cdots\}$
		- allo stesso modo posso rappresentare in modo implicito i numeri pari $\mathbb{P}$
			- con una funzione posso identificare i pari, per esempio --> `fun pari(x: integer): boolean {pari := (x mod 2 = 0)`
		- per i linguaggi esistono 2 tecniche
			1. generativo/sintetico, che definisce il linguaggio da una struttura detta grammatica
			2. riconoscitivo/analitico, che definisce il linguaggio da una struttura finita detta automa
		- osservazione: non tutti i linguaggi possono essere generati da grammatiche o riconosciuti da automi
			- $|A^{*}| = |\mathbb{N}|$
			- $\mathbf{P}(A^{*})$ è l'insieme delle parti di tutti i linguaggi sull'alfabeto $A$, e sappiamo che l'insieme potenza è equipotente a $\mathbb{R}$ (infinito più grande di $\mathbb{N}$)
			- fondamentalmente ci sono tantissimi linguaggi che non possono essere rappresentati finitamente, da una grammatica o da un automa
				- paragone con funzioni matematiche cui maggior parte non può essere tradotta in codice
			- argomento diagonale di Cantor applicato ai linguaggi --> ci dimostra che l'insieme dei linguaggi non è numerabili (ma equipotente a $\mathbb{R}$)
- **definire finitamente un linguaggio**
	- esempio con le palindrome
		- prendiamo alfabeto $A = \{a, b\}$
		- definiamo le palindrome come $L = \{\epsilon, a, b, aa, bb, aba, bab, aaa, bbb, abba, baab, aaaa, bbbb, \cdots\}$
		- una palindroma allora può essere:
			- $\epsilon$
			- $a$
			- $b$
			- $a$-palindroma-$a$
			- $b$-palindroma-$b$
		- qualunque palindroma può essere generata con queste 
		- usiamo la **Backus-Naur Form** (BNF): $$<P> ::= \epsilon | a | b | a <P> a | b <P> b$$
		- la grammatica si definisce allo stesso modo: $$P \to \epsilon | a | b | aPa | bPb$$
			- nota che si tratta di una definizione ricorsiva (strutturale)
		- alternativamente si può definire assiomaticamente e con regole d'inferenza
			- assiomi: $\epsilon \in L(P)$, $a \in L(P)$, $b \in L(P)$
			- inferenze: $w \in L(P) \implies awa \in L(P)$, $w \in L(P) \implies bwb \in L(P)$
	- esempio con espressioni aritmetiche formate a partire dalle variabili $a$ e $b$ e con gli operatori $*, +$ e le parentesi $()$
		- BNF
			- $<E> ::= a|b|<E>*<E>|<E>+<E>|(<E>)$
		- grammatica
			- $E \to a|b|E*E|E+E|(E)$
		- assiomi e inferenza
	- ora, come deriviamo una stringa
		- $P \to \epsilon | a | b | aPa | bPb$
		- ora vogliamo dimostrare per esempio che $abba \in L(P)$, questa si chiama **derivazione**
		- $$P \implies aPa \implies abPba \implies abba$$
			- si usano le regole di inferenza sui singoli passaggi (non sono implicazioni, ma derivazioni), e questi sono rispettivamente
				1. $P \to aPa$
				2. $P \to bPb$
				3. $P \to \epsilon$
		- altro esempio, con espressioni aritmetiche
	- definiamo finalmente le **grammatiche**
		- ci sono tante classi:
			- regolari, libere (da contesto), dipendenti dal contesto, monotone, generali (o "a struttura di frase")
				- noi faremo bene solo le regolari e le libere
				- nota bene: più le grammatiche sono potenti (espressive), più diventa difficile analizzarle e dimostrarne la correttezza
			- tutte seguono lo stesso pattern, differenziandosi solo per come sono caratterizzate le _produzioni_ (o regole) --> le vedremo in seguito come _classificazione di Chomsky_
		- definiamo le grammatiche libere da contesto
			- è una quadrupla $(NT, T, R, S)$ dove
				- $NT$ è un insieme finito di simboli non terminali (di solito lettere maiuscole)
				- $T$ è un insieme finito di simboli terminali (di solito lettere minuscole)
				- $S \in NT$ è detto simbolo iniziale
				- $R$ è un insieme finito di produzioni (o regole) della forma $$V \to w : w \in NT \land V \in (T \cup NT)^{*}$$
			- esempio
				- $G = (\{S\}, \{a, b, +, *\}, S, R)$ con $R = \{S \to a, S \to b, S \to S+S, S \to S*S\}$, o più semplicemente (riassunto della grammatica) $S \to a|b|S+S|S*S$ dove $S$ è il simbolo iniziale
			- esempio
				- $G_{1} = (\{S, A\}, \{a, b\}, S, R_{1})$ con $R_{1} = \{S \to aAb, A \to aAb, A \to \epsilon\}$, o più semplicemente (riassunto della grammatica) $S \to aAb$ e $A \to aAb|\epsilon$
			- esempio
				- $G_{2} = (\{S, A, B\}, \{a, b\}, S, R_{2})$ con $R_{2} = \{S \to AB, A \to aA, A \to a, B \to bB, B \to b\}$, o più semplicemente $S \to AB$, $A \to aA|a$, $B \to bB|b$
			- altro ultimo esempio
			- il problema, ora, è:
				- dalla grammatica capire il linguaggio che genera
				- dal linguaggio capire da che grammatica è generato
			- esempio
				- prendiamo la seguente grammatica
					- $E \to I|E+E|E*E|-E|(E)$
					- $I \to a|b|Ia|Ib$
				- $L(I) = \{a, b\}^{+}$ è l'insieme degli identificatori, ossia tutte le possibili sequenze non vuote di $a$ e $b$, è un insieme infinito
				- $L(E)$ è l'insieme delle espressioni aritmetiche costruite sugli identificatori
		- formalizziamo ora le derivazioni
			- data $G=(NT, T, R, S)$ libera da contesto, dichiamo che da $V$ si deriva immediatamente $w$ (o anche $v$ si riscrive in un passo in $w$), e lo denotiamo con $v \implies w$, se $v = xAy \ \ \ (A \to z) \in R \ \ \ w = xzy$
			- diciamo invece che da $v$ si deriva $w$ e lo denotiamo con $v \implies^{*} w$ se esiste una sequenza finita eventualmente vuota di derivazioni immediate $v \implies w_{0} \implies w_{1} \implies \cdots \implies w$
				- $\implies^{*}$ è la chiusura riflessiva e transitiva della relazione $\implies$
			- esempio
				- $S + S \implies \cdots \implies S*S + a*S$
				- quindi si scrive $S+S \implies^{*} S*S + a*S$
			- altro esempio
				- nota bene: posso partire anche da simboli non iniziali --> otterrò delle derivazioni "valide" per le regole, ma che non appartengono alla grammatica
			- altro esempio
				- nota bene: posso prendere strade di derivazione diverse ed ottenere stesse stringhe
	- definiamo il **linguaggio generato** da una grammatica $G$
		- definizione: il linguaggio generato da una grammatica $G = (NT, T, R, S)$ è l'insieme $L(G) = \{w \in T^{*} | S \implies^{*} w\}$ dove $T^{*}$ è l'insieme dei terminali
			- quindi è l'insieme di parole che posso derivare a partire dal simbolo iniziale
		- ora possiamo affrontare le domande iniziali:
			- come faccio a determinare $L(G)$?
			- come faccio a verificare se $w \in L(G)$?
		- risposte:
			- ci sono tecniche opportune, in alcuni casi anche efficienti
			- ma l'algoritmo _naif_ è: partire da $S$ e provare ad applicare in tutti i modi possibili le produzioni per trovare una derivazione che generi $w$ (_nondeterminismo_ $\implies$ _backtracking_, per cui non è efficiente)
		- esempio di applicazione dell'algoritmo naif
			- $G_{3} = S \to aSb | ab$
			- le derivazioni sono "semplici", prevedibili
			- infatti determinare il linguaggio della grammatica $L(G_{3})$ è facile una volta che si riconosce il pattern: $L(G_{3}) = \{a^{n}b^{n} | n \geq 1\}$
		- da un altro esempio notiamo una cosa importante
			- _esistono grammatiche formalmente diverse ma che generano lo stesso linguaggio_: in tal caso si dice che le grammatiche sono equivalenti
			- addirittura si può dimostrare che esistono infinite grammatiche diverse che generano lo stesso linguaggio
				- ovvio, basta aggiungere "spazzatura", tipo non-terminali non raggiungibili a partire dal simbolo iniziale!
		- altro esempio
			- $G_{2} = S \to AB, A \to aA|a, B \to bB|b$
			- si nota che $L(S) = L(A) \cdot L(B)$
			- notiamo anche che $L(A) = \{a^{n}|n \geq 1\}$ e $L(B) = \{b^{n}|n \geq 1\}$
			- allora $L(G_{2}) = L(S) = \{a^{n}b^{m} | n, m \geq 1\}$
		- altro esempio
			- $G = S \to AB, A \to aA|\epsilon, B \to Bb|\epsilon$
			- ottengo $L(G) = \{a^{n}b^{m} | n, m \geq 0\}$
			- nota bene: $\epsilon \in L(G)$
		- altro esempio
			- $G = S \to AB, A \to aAb|\epsilon, B \to bB|\epsilon$
			- ottengo $L(G) = \{a^{n}b^{n+m} | n, m \geq 0\} = \{a^{n}b^{m} | m \geq n \geq 0\}$
		- ora vediamo esempi per capire la nozione contraria: data il linguaggio capire la grammatica
			- $L = \{a^{n}b^{m} | n \geq m \geq 0\}$
			- ottengo $G = S \to AB, A \to \epsilon|aA, B \to aBb|\epsilon$ (simmetrica alla precedente)
		- altro esempio
			- $L = \{a^{2n+1} | n \geq 0\} = \{a, aaa, aaaaa, \cdots\}$
			- $S \to a | aaS$
		- altro esempio
			- $L = \{a^{2n} b^{2m+1} | n, m \geq 0\}$
			- $S \to aaS | bB$
			- $B \to \epsilon | bbB$
		- altro esempio, stavolta di un linguaggio finito
			- $L = \{ab, ac, ad\}$
			- caso triviale: $S \to ab|ac|ad$, oppure $S \to aA, A \to b, c, d$
		- altro esempio
			- $L = \{a^{2n} b^{m} c^{2m} | n \geq 0, m \geq 1\}$
			- $S \to aaS | bBcc$, $B \to \epsilon | bBcc$
		- altro esempio
			- $L = \{a^{n} b^{k} c^{n} | n \geq 0, k \geq 1\}$
			- $S \to aSc | B$
			- $B \to b | bB$
		- altro esempio
			- $L = \{a^{n}b^{n}c^{m}d^{m} | n, m \geq 0\}$
			- $S \to AB$
			- $A \to aAb|\epsilon$
			- $B \to cBd|\epsilon$
		- altri esempi, sempre più complessi

## Domande

## Referenze
