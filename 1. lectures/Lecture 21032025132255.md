---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-delle-probabilità-e-statistica
date: 21-03-2025 13:22:55
teacher: stefano.pagliarani9@unibo.it
mod: 2
---
# Lezione
---
## Concetti
- **variabili aleatorie discrete**
	- insieme di supporto $S_{X}$ sono tutti i valori possibili della variabile aleatoria con probabilità positiva ($> 0$); matematicamente $S_{X} = \{x \in \mathbb{R} | \mathbb{P}(X = x) > 0\}$
	- le variabili aleatorie discrete hanno $S_{X}$ finito o numerabile
	- funzione di ripartizione: $F_{X}: \mathbb{R} \to [0, 1]$
		- $F_{X}(x) = \mathbb{P}(X \leq x)$, con le sue proprietà fatte la scorsa volta
	- funzione di ripartizione per variabile aleatorie discrete
		- teorema --> le seguenti affermazioni sono equivalenti:
			- $X$ è una variabile aleatoria discreta;
			- $F_{X}$ è costante a tratti (a scalini) --> $\forall x \in S_{X}, p_{X}(x) = F_{X}(x) - F_{X}(x^{-})$
				- dove $p_{X}(x) := \mathbb{P}(X = x)$, e $F_{X}(x^{-}) := \lim_{y \to x^{-}}F(y)$
			- $\mathbb{P}(X \in B) = \sum\limits_{x \in S_{X} \cap B} p_{X}(x)$
		- esempio: lancio di un dado
			- $\Omega = \{1, 2, 3, 4, 5, 6\}$
			- $X(w) = \begin{cases} 1 & w \in \{2, 4, 6\} \\ -1 & w \in \{1, 3, 5\} \end{cases}$
			- probabilità uniforme, quindi $\mathbb{P}(\{w\}) = \frac{1}{6}$
			- $X$ è discreta? sì, perché può assumere 2 valori
			- bastava questo esempio, si è capito tutto
- **media e varianza**
	- data una distribuzione è utile avere degli indici associati ad essa
	- il valore atteso può essere visto come una media pesata
		- presa una variabile aleatoria possiamo fare la media dei suoi output, pesati sulla loro probabilità
	- definizione: sia $X: \Omega \to \mathbb{R}$ variabile aleatoria discreta, la sua **media** (o valor medio, valor atteso, speranza, ...) è definita come $$\mathbb{E}[X] := \sum\limits_{x \in S_{X}} x \cdot p_{X}(x)$$
		- nell'esempio del lancio del dado precedente, avremo $\mathbb{E}[X] = 0$
		- nota bene: la media non necessariamente è uno dei valori della variabile aleatoria discreta
		- altro esempio: $X$ ha valori equiprobabili --> $p_{X}(x) = p \in [0, 1]$, quindi sarà costante
			- una tale distribuzione esiste solo se $S_{X} = \{x_{1}, \cdots, x_{n}\}$ e $p_{X}(x_{k}) = \frac{1}{n}$
			- la media diventa aritmetica: $$\mathbb{E}[X] = \sum\limits_{k=1}^{n} p_{X}(x_{k})x_{k} = \frac{1}{n} \sum\limits_{k=1}^{n}x_{k}$$
		- altro esempio: $X$ funzione indicatrice di un evento $A$, ossia $X = \mathbb{1}_{A}$
			- $\mathbb{E}[X] = 1 \mathbb{P}(A) + 0 (1 - \mathbb{P}(A)) = \mathbb{P}(A)$
		- teorema di linearità della media: se abbiamo $X, Y$ v.a. discrete, allora $$\mathbb{E}[\alpha X + \beta Y] = \alpha \mathbb{E}[X] + \beta \mathbb{E}[Y]$$
			- dimostrazione ma nel caso in cui $Y = g(X)$
				- osserviamo che $S_{Y} = g(S_{X})$
				- per definizione $$\mathbb{E}[\alpha X + \beta g(X)] = \sum\limits_{x \in S_{X}}[\alpha x + \beta g(x)] \cdot p_{X}(x) = \alpha \sum\limits_{x \in S_{X}}x p_{X}(x) + \beta \sum\limits_{x \in S_{X}} g(x) p_{X}(x) = \alpha \mathbb{E}[X] + \beta \mathbb{E}[Y]$$
	- ma quanto è probabile che l'esito sia diverso dal valore atteso? si chiama **varianza**
		- l'idea è di fare una media degli errori quadrati rispetto al valore atteso
		- definizione: sia $X$ variabile aleatoria discreta, con supporto $S_{X}$, allora la varianza di $X$ è $$var(X) := \mathbb{E}[(X - \mathbb{E}[X])^{2}]$$
		- si può anche indicare con $\sigma_{X}^{2}$
		- osservazione: $var(X) = \sum\limits_{x \in S_{X}} (x - \mathbb{E}[X])^{2} \cdot p_{X}(x)$
		- esempio: $X = 0$, costante uguale a 0, allora $S_{X} = \{0\}$
			- $\mathbb{E}[X] = 0$
			- $var(X) = (0 - 0)^{2} = 0$
		- altro esempio, quello del lancio del dado con -1 e 1, che ha la stessa media di prima ma diversa varianza
			- $\mathbb{E}[X] = 0$
			- $var(X) = \frac{1}{2} + \frac{1}{2} = 1$
			- ora, definiamo $Y = 2X$, una scommessa più rischiosa
				- avremo $\mathbb{E}[Y] = 0$ (si ricava anche non intuitivamente dalla linearità!)
				- mentre $var(Y) = 4$
		- osservazione: se togliessi il quadrato otterrei sempre 0, ossia $\mathbb{E}[X - \mathbb{E}[X]] = 0$
		- osservazione: se usassi invece il valore assoluto, l'idea ci starebbe ma per ragioni matematiche si preferisce comunque usare il quadrato
			- infatti il valore assoluto in 0 non è derivabile; il quadrato è sempre derivabile e fa circa lo stesso lavoro
		- quindi, mettendo il quadrato si hanno delle belle proprietà, ma bisogna poi fare la radice quadrata per ottenere il risultato reale:
			- definizione: la quantità $\sigma(X) = \sqrt{var(X)}$ si chiama **deviazione standard**
		- proposizione: $var(X) = \mathbb{E}[X^{2}] - (\mathbb{E}[X])^{2} = \sum\limits_{x \in S_{X}}x^{2}p_{X}(x) - (\sum\limits_{x \in S_{X}} x p_{X}(x))^{2}$
			- dimostrazione: $var(X) = \mathbb{E}[(X - \mathbb{E}[X])^{2}] = \mathbb{E}[X^{2} - 2\mathbb{E}[X]X + (\mathbb{E}[X])^{2}] = \mathbb{E}[X^{2}] - \mathbb{E}(2\mathbb{E}[X]X) + \mathbb{E}[(\mathbb{E}[X])^{2}]$
				- allora diventa $\mathbb{E}[X^{2}] - 2(\mathbb{E}[X])^{2} + (\mathbb{E}[X])^{2}$
				- e questo conclude la dimostrazione
		- teorema: sia $X$ variabile aleatoria discreta, allora valgono
			1. $var(X) \geq 0$
			2. $var(X) = 0 \iff X \text{ costante}$
			3. $var(aX + b) = a^{2} var(X)$
			- dimostrazione

## Domande
- sta tirando dei calci alla cattedra

## Referenze
