---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-numerico
date: 26-09-2024 09:20:21
teacher: elena.loli@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- ripasso metodo dell'iterazione
- ripasso generale
	1. metodo di bisezione - metodo iterativo falso, ho un'iterazione ma non ho un punto iniziale (è un intervallo)
	2. metodo del punto fisso
	3. metodo di Newton (estensione del punto fisso)
		- nota bene: il _backward error_ è il valore $|f(x_{k})|$, mentre l'_errore stimato_ è $|\frac{f(x_{k})}{f'(x_{k})}|$; il criterio di arresto è sull'errore stimato
- formalizzazione del concetto di **velocità di convergenza**
	- $x^{*}$ è la soluzione esatta; $x_{k}$ è la soluzione all'iterazione $k$
	- $|x_{k+1} - x^{*}| = |E_{k+1}|$ ossia l'errore assoluto al passo $k+1$
	- relazione $|E_{k+1}| \leq C |E_{k}| \leq C^{2}|E_{k-1}| \leq \cdots \leq C^{k}|E_{0}|$
	- nella bisezione si ha $C = \frac{1}{2}$
	- nel punto fisso $C$ è la costante di contrazione, calcolata come $|g'(x)| < C \ \ \forall x \in [a, b]$
	- se visualizziamo a grafico gli errori dei due metodi in funzione di $k$, vediamo che nel metodo del punto fisso l'iterazione converge più velocemente a 0 che il metodo di bisezione
		- per cui a parità di iterazioni $k$, il metodo del punto fisso fornisce un errore più piccolo di quello di bisezione
		- si tratta sempre tuttavia di iperboli
	- si dice che un metodo iterativo ha _ordine di convergenza $p$_ se $$|E_{k+1}| \leq C | E_{k}|^{p}$$
		- dove $p > 1$
		- in particolare:
			- $p = 1 \implies$ _convergenza lineare_ (dev'essere $C < 1$, altrimenti l'errore aumenta)
			- $1 < p < 2 \implies$ _convergenza superlineare_
			- $p = 2 \implies$ _convergenza quadratica_
		- esempi:
			- il metodo di bisezione ha convergenza lineare, con $C = \frac{1}{2}$
			- il metodo del punto fisso ha convergenza lineare, con $C$ costante di contrazione
			- il metodo di Newton ha convergenza quadratica --> per questo è il metodo più veloce
- **soluzione sistemi lineari**
	- definizione sistema lineare
	- ci occupiamo di sistemi lineari quadrati ($m = n$), in notazione matriciale $A\underline{x} = \underline{b}$ con
		- $A \in M_{n}(\mathbb{R})$ matrice dei coefficienti
		- $\underline{x}$ vettore delle incognite
		- $\underline{b}$ colonna dei termini noti
	- si ha che:
		1. il sistema $Ax = b$ ha una ed una sola soluzione $\iff$ $A$ è _non singolare_ ($\det(A) \neq 0$) (lo sappiamo dal [[Determinante#Teoremone|teoremone]])
		2. algoritmo per calcolare la soluzione
		3. stima errore inerente
	- algoritmi
		- $Ax = b \iff A^{-1}Ax = A^{-1}b \iff x = A^{-1}b$, tuttavia questo approccio non viene considerato perché calcolare la matrice inversa è dispendioso --> complessità computazionale $O(n^{3})$
		- due classi di metodi:
			1. _metodi diretti_, + accurati (no errore di troncamento) - efficienti
			2. _metodi iterativi_, - accurati + efficienti
		- metodi diretti: basati sull'idea di fattorizzare la matrice $A$, ossia scriverla come prodotto di 2 matrici
			- vedremo la **fattorizzazione LU**, ossia $A = L \cdot U$
			- l'idea è che $L$ e $U$ sono [[Matrice triangolare|matrici triangolari]], rispettivamente inferiore e superiore
			- steps:
				1. costruisco $E_{1}$ come matrice triangolare inferiore con tutti 1 sulla diagonale e con elementi sulla prima colonna calcolati come:
					- $e_{21} = - \frac{a_{21}}{a_{11}}$
					- $e_{31} = - \frac{a_{31}}{a_{11}}$
					- questo perché se moltiplico $E_{1}$ con $A$ ottengo $A$ con elementi nulli sulla prima colonna (l'intenzione è di triangonalizzarla)
				2. costruisco $E_{2}$ allo stesso modo di $E_{1}$, ma con elementi sulla seconda colonna calcolati come:
					- $e_{32} = - \frac{a_{32}}{a_{22}}$
					- in questo modo ottengo che $E_{2}E_{1}A$ è una matrice triangolare superiore --> $= U$
				3. ora trovo $L$ con $L = E_{1}^{-1} \cdot E_{2}^{-1}$
				4. risolvo $L(U(x)) = b$, con due sistemi
					- prima risolvo $Ly = b$
					- quindi risolvo $Ux = y$
					- e risolvere due sistemi triangolare, come sappiamo dalla teoria (in quanto a scala), ha costo computazionale più basso di un sistema non triangolare
						- basta fare sostituzioni dal basso (triangolare superiore) o dall'alto (triangolare inferiore)
					- `y = np.linalg.solve(L, b)`
					- `x = np.linalg.solve(U, y)`
			- ma si possono fattorizzare tutte le matrici $A$ non singolari in $LU$? solo alcune matrici - quelle che hanno tutti i minori principali diversi da 0
			- se l'elemento diagonale $a_{11}$ è molto piccolo, $e_{i1} = - \frac{a_{i1}}{a_{11}}$ diventa molto grande --> potremmo perdere cifre decimali, portando ad errori algoritmi molto grandi --> infatti vale per $a_{11}$ ma anche $a_{22}, a_{33}, \cdots$
				- quindi viene fatta una modifica all'algoritmo per allargare il dominio di matrici fattorizzabili --> fattorizzazione LU con scambio delle righe (se nella diagonale c'è uno 0, si scambia la riga con un'altra che non abbia lo 0)
				- questi scambi di righe, di cui bisogna tenere conto per il risultato finale, vengono salvate in una matrice di permutazione $P$, una matrice identità di ordine $n$ con eventuali righe scambiate
					- avremo allora $P \cdot A = L \cdot U$ e quindi $A = P^{-1}LU$
					- ma tanto $P = P^{-1}$, per cui $A = PLU$
				- nota bene: se quindi $P \neq I$, allora devi risolvere $y = L|Pb$
			- ad ogni modo, da una complessità di $O(n^{3})$ si passa con questo algoritmo a $O\left(\frac{n^{3}}{3}\right) + O\left(\frac{n^{2}}{2}\right) + O\left(\frac{n^{2}}{2}\right) = O(n^{3})$ (non è cambiato un cazzo)

## Domande

## Referenze
