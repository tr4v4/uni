---
tags:
  - category/lecture
  - status/finished
  - topic/algoritmi-e-strutture-dati
date: 15-04-2024 09:17:54
teacher: gianluigi.zavattaro@unibo.it
mod: 2
---
# Lezione
---
## Concetti
- [[Algoritmi greedy|algoritmi greedy]]
	- esempio di applicazione: problema del resto
		- vogliamo erogare il minimo numero intero di monete necessarie per raggiungere un resto di $R$ centesimi di euro, usando solo monete da 50c, 20c, 10c, 5c, 2c, 1c (disponendo di un numero infinito di monete di ciascun taglio)
		- risolviamo con approccio greedy --> prendiamo ogni volta la moneta di taglio massimo, la più grande rispetto al resto rimanente, e sottraiamo il suo valore; _scegliamo fondamentalmente ogni volta la strada locale migliore, con la sicurezza che la soluzione ottenuta alla fine sarà la strada globale migliore_;
		- <u>attenzione</u>: questo approccio non funziona con tutti gli insiemi di tagli di moneta!
			- un modo per farlo funzionare nel caso generale è attraverso la programmazione dinamica
		- algoritmo risolutivo
		- situazioni in cui questo approccio non funziona:
			- i sistemi monetari per i quali l'algoritmo greedy fornisce la soluzione ottima si chiamano **sistemi monetari canonici**
			- esempi di sistemi in cui greedy fallisce
				- erogare 6 con tagli 4, 3, 1 ---> greedy: 4+1+1, ottimo: 3+3;
				- erogare 6 tagli con 5, 2 ---> greedy: 5+errore, ottimo: 2+2+2;
	- altro esempio: **problema di scheduling** (o Shortest Job First)
		- lo studieremo bene al corso di sistemi operativi, perché gli [[SO]] necessitano di schedulare i processi per capire quali far eseguire prima al processore
		- algoritmo di scheduling
			- abbiamo $n$ job $p_{1}, \cdots, p_{n}$
			- ogni $p_{i}$ job ha un tempo di esecuzione `t[i]`
			- vogliamo _minimizzare il tempo medio di attesa_
			- <u>nota bene</u>: i job arrivano tutti contemporaneamente, per cui non possiamo usare le [[Coda con priorità|code con priorità]] rispetto al tempo di arrivo
			- due esempi di ordinamento e tempo medio di attesa
			- notiamo come _la situazione migliore si ottiene eseguendo i job in ordine crescente di tempo di esecuzione_ (infatti si chiama Shortest Job First)
				- dimostrazione di ottimalità: [[Regole di inferenza del RAA|per assurdo]] immaginiamo una soluzione ottimale non greedy, che esegue un job lungo $A$ prima di uno corto $B$; ora immaginiamo di scambiare $A$ con $B$ --> otteniamo una soluzione con un tempo medio di attesa migliore, un ottimo globale, per cui assurdo
	- altro esempio: **problema di compressione** (o Codifica di Huffman)
		- vogliamo rappresentare sequenze di caratteri secondo una tecnica detta _codifica di caratteri_
			- funzione di codifica: $f(c) = x$, dove
				- $c$ è un carattere dell'alfabeto $\Sigma$
				- $x$ è una rappresentazione binaria del carattere $c$
			- per cui una sequenza di caratteri $c_{1}, \cdots, c_{n}$ viene codificata con la sequenza di bit $f(c_{1}), \cdots, f(c_{n})$
			- data una qualsiasi codifica dev'essere sempre possibile decodificarla durante la lettura sequenziale _bit-dopo-bit_
		- problema: data una sequenza $c_{1}, \cdots, c_{n}$ definire una funzione $f$ che minimizza la lunghezza della codifica $f(c_{1}), \cdots, f(c_{n})$
			- esempi di codifica:
				- ASCII --> 8 bit per carattere, quindi dimensione totale per $n$ caratteri è $8n$ bit
				- ternaria --> 3 bit per carattere, quindi dimensione totale per $n$ caratteri è $3n$ bit
			- ma queste sono codifiche statiche!
			- usiamo codici a lunghezza variabile
				- alcuni caratteri avranno una codifica corta, altri una codifica lunga
				- questa risulta essere ottimale, infatti il costo medio basato sulla frequenza dei caratteri della codifica è $2.24n$
				- in particolare ci interessano i codici "a prefisso" --> _nessun codice è un prefisso di un altro codice_
					- questa è una condizione necessaria per permettere sempre la decodifica durante la lettura bit-dopo-bit!
				- rappresentiamo questi codici "a prefisso" con degli alberi
					- ogni carattere è foglia, non può essere nodo altrimenti farebbe da prefisso a un altro carattere
					- come criterio di apparizione dei caratteri lungo l'albero usiamo la loro frequenza nell'alfabeto
					- costruzione degli alberi:
						1. costruisco una lista ordinata di nodi in cui ogni nodo contiene il carattere e la sua frequenza;
						2. rimuovo i due nodi con frequenze minori;
						3. li collego a un nodo padre etichettato con la frequenza combinata (sommata);
						4. ripeto gli step 2-4 fino a quando non resta un solo nodo nella lista;
					- una volta costruito l'albero delle frequenze il codice è semplice da comporre: `left` è 0; `right` è 1
					- costruiamo allora l'_algoritmo di Huffman_ basandoci sulle code con priorità! infatti vogliamo cercare il minore dei nodi, mantenendo l'ordine sulla rimozione;
						- algoritmo
						- costo: $O(n\log{n})$
					- nota che l'algoritmo usa un approccio greedy --> prendiamo sempre i caratteri con frequenza minore e non sbagliamo mai
	- vantaggi e svantaggi

## Domande
- indice di golosità
- "out of the box" counter = 2

## Referenze
