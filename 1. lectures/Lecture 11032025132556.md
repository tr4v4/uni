---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-delle-probabilità-e-statistica
date: 11-03-2025 13:25:56
teacher: elena.bandini7@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- **variabili aleatorie**
	- come per gli eventi, daremo due definizioni:
		1. un'affermazione --> una variabile aleatoria è un'affermazione che riguarda il risultato dell'esperimento aleatorio; tale affermazione identifica uno e un solo numero, una volta noto l'esito dell'esperimento --> rispondiamo alla domanda "quanto vale"
		2. in termini matematici --> una v.a. è rappresentata da una funzione $X: \Omega \to \mathbb{R}$
	- notazione: per gli eventi si usano "A, B, C", per le v.a. si usano "X, Y, Z"
	- osservazione: qualunque funzione da $\Omega$ in $\mathbb{R}$ è una variabile aleatoria
		- nota bene: in realtà si dovrebbe dire che "ogni funzione è misurabile"; è la stessa questione degli eventi, per cui ogni sottoinsieme di $\Omega$ è un evento ma in realtà se $\Omega$ è finito o massimo numerabile (per l'additività numerabile)
	- esempio: lancio di 2 dadi
		- una v.a. possibile è $X =$ "la somma dei due lanci"
			- per cui $X = 3$ è un evento
		- un'altra $Y =$ "prodotto dei due lanci"
		- un'altra $Z =$ "risultato del primo lancio"
		- analizziamo questo caso
			- $\Omega = DR_{6,2} = \{(w_{1}, w_{2}) | w_{i} \in \{1, 2, 3, 4, 5, 6\}\}$
			- $X((w_{1}, w_{2})) = w_{1} + w_{2}$
			- $Y((w_{1}, w_{2})) = w_{1} \cdot w_{2}$
			- $Z((w_{1}, w_{2})) = w_{1}$
	- ci interessano veramente, perché in realtà scopriremo che sono una generalizzazione degli eventi
		- infatti _genereremo degli eventi a partire da delle variabili aleatorie_
	- **variabili aleatorie costanti**
		- $a \in \mathbb{R}. \ \ \ X(w) = a \ \ \ \forall w \in \Omega$
		- diremo che $X$ è una variabile aleatoria _quasi certamente costante_ se $\mathbb{P}(X(w) = a) = 1$
		- esempio: lancio di un dado
			- $\Omega = \mathbb{R}$, e definisco $\mathbb{P}$ come
				- $\mathbb{P}(\{1\}) = \cdots = \mathbb{P}(\{6\}) = \frac{1}{6}$
				- $\mathbb{P}(\{x\}) = 0 \ \ \ \forall x \neq 1, 2, 3, 4, 5, 6$
			- fisso $a \in \mathbb{R}$
			- voglio costruire $X$ v.a. tale che $\mathbb{P}(X(w) = a) = 1$
			- allora facciamo $$X(w) = \begin{cases} a & w \in \{1, 2, 3, 4, 5, 6\} \\ w & w \notin \{1, 2, 3, 4, 5, 6\} \end{cases}$$
			- in questo modo $X$ è _quasi certamente costante_! Infatti $\mathbb{P}(X = a) = \mathbb{P}(\{w \in \Omega : X(w) = a\}) = \mathbb{P}(\{1, 2, 3, 4, 5, 6\}) = 1$
	- **variabili aleatorie indicatrici** (o di Bernoulli)
		- sia $A \subseteq \Omega$ evento, e $X(w) = \mathbb{1}_{A}(w) = \begin{cases} 1 & w \in A \\ 0 & w \notin A \end{cases}$
		- è con questa variabile aleatoria che capiamo che le v.a. sono generalizzazioni degli eventi!
		- infatti tutta l'informazione dell'evento $A$ è contenuta nella variabile aleatoria
		- quindi dato un evento posso costruire la variabile aleatoria che la descrive: posso fare il contrario? Sì!
			- se quindi ho $X$ v.a., posso ottenere l'evento associato? com'è fatto?
			- le v.a. sono generalizzazioni del concetto di evento
	- **eventi associati/generati alle/dalle variabili aleatorie**
		- presa una variabile aleatoria si possono generare una moltitudine di eventi! al contrario, invece, da un evento si ha una sola variabile aleatoria (di Bernoulli)
		- chiamiamo $\sigma(X)$ gli eventi generati/associati alla v.a. $X$
		- si dice che $E \subseteq \Omega$ è un evento generato da $X$ se $\exists B \subseteq \mathbb{R} : E = \{w \in \Omega : X(w) \in B\}$
			- è la controimmagine di $X$ su $B$! ossia $X^{-1}(B)$
		- esempio: lancio di due dadi
			- $X =$ "risultato della somma dei lanci"
			- $A =$ "la somma è 3" --> $\{X \in \{3\}\} = X^{-1}(\{3\})$
			- $B =$ "la somma è $\leq$ 5" --> $\{X \in (-\infty, 5]\}$
		- osservazione: per ogni $X: \Omega \to \mathbb{R}$ variabile aleatoria, ho $\Omega = \{X \in \mathbb{R}\}$ e $\varnothing = \{X \in \varnothing\}$
		- $X$ v.a. costante tale che $X(w) = a$, allora cos'è $\sigma(X)$?
			- se fisso $B \subseteq \mathbb{R}$, allora $X^{-1}(B) = \begin{cases} \Omega & a \in B \\ \varnothing & a \notin B \end{cases}$
			- quindi $\sigma(X) = \{\Omega, \varnothing\}$
		- $X$ v.a. indicatrice, allora cos'è la $\sigma(X)$?
			- $X^{-1}(B) = \begin{cases} A & 1 \in B, 0 \notin B \\ A^{C} & 1 \notin B, 0 \in B \\ \Omega & 1 \in B, 0 \in B \\ \varnothing & 1 \notin B, 0 \notin B \end{cases}$
		- osservazione:
			1. $\mathbb{P}(X \leq x) = \mathbb{P}(X < x) + \mathbb{P}(X = x)$
			2. $\mathbb{P}(X \leq x) = 1 - \mathbb{P}(X > x)$
			- con dimostrazione (semplice)
	- **distribuzione (o legge) di una variabile aleatoria**
		- $(\Omega, \mathbb{P})$ spazio di probabilità, e $X: \Omega \to \mathbb{R}$ v.a.
		- definiamo _legge di $X$_ la probabilità $\mathbb{P}_{X}: \mathscr{P}(\mathbb{R}) \to [0, 1]$ definita come $\mathbb{P}_{X}(B) := \mathbb{P}(X^{-1}(B))$
		- si scrive $X \sim \mathbb{P}_{X}$ e si legge "$X$ ha la legge $\mathbb{P}_{X}$"
		- dimostrare che la legge di $X$ è una probabilità
		- è comodo, perché ci consente di lavorare con insiemi reali --> con le probabilità su $\mathbb{R}$ posso lavorare sugli intervalli
		- osservazione: conoscere $\mathbb{P}_{X}(B) \ \ \ \forall B \subseteq \mathbb{R}$ equivale a conoscere $\mathbb{P}_{X}((-\infty, x]) \ \ \ x \in \mathbb{R}$
			- si dimostra che la legge $\mathbb{P}_{X}$ di una v.a. $X$ è caratterizzata dalla funzione $F_{X}(x) := \mathbb{P}_{X}((-\infty, x]) = \mathbb{P}(X \leq x)$, che è $F_{X}: \mathbb{R} \to [0, 1]$
			- si chiama funzione di ripartizione

## Domande

## Referenze
