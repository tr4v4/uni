---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-delle-probabilità-e-statistica
date: 11-04-2025 13:18:34
teacher: elena.bandini7@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- definiamo gli indici delle variabili aleatorie continue
	- equivalenti a valore atteso e varianza per le variabili aleatorie discrete
	- caso discreto
		- $\mathbb{E}[X] = \sum\limits_{i} x_{i} p_{X}(x_{i})$
			- nel caso numerabile, è ben definito se $\sum\limits_{i} |x_{i}| p_{X}(x_{i}) < + \infty$
			- vale che (già visto) $\mathbb{E}[h(X)] = \sum\limits_{i} h(x_{i}) p_{X}(x_{i})$
		- $Var(X) = \mathbb{E}[(X - \mathbb{E}[X])^{2}] = \mathbb{E}[X^{2}] - (\mathbb{E}[X])^{2}$
	- caso continuo
		- $\mathbb{E}[X] = \int_{\mathbb{R}} x f_{X}(x) \ dx$
			- è ben definito  se $\int_{\mathbb{R}} |x| f_{X}(x) \ dx < +\infty$
			- vale che (difficile da dimostrare) $\mathbb{E}[h(X)] = \int_{\mathbb{R}} h(x)f_{X}(x) \ dx$
		- $Var(X) = \int_{\mathbb{R}} x^{2}f_{X}(x) \ dx - \left(\int_{\mathbb{R}} x f_{X}(x) \ dx\right)^{2}$
- distribuzioni notevoli continue
	- uniforme
		- $S_{X} = (a, b)$
		- $f_{X}(x) = \frac{1}{b-a} \mathbb{1}_{(a, b)}(x)$
		- nota bene: non cambia se gli estremi sono inclusi
		- $F_{X}(x)$?
			- $x < a \implies F_{X}(x) = 0$
			- $x \geq b \implies F_{X}(x) = 1$
			- $x \in [a, b) \implies F_{X}(x) = \int_{a}^{x} \frac{1}{b-a} \ dy = \frac{x-a}{b-a}$
		- $\mathbb{E}[X] = \frac{a+b}{2}$ (fare tutto il calcolo)
		- $Var(X) = \frac{a^{2} - 2ab + b^{2}}{12} = \frac{(a-b)^{2}}{12}$
		- osservazione sulla generazione di numeri pseudocasuali
			- come simulare una v.a.?
			- in generale si sa generare una variabile aleatoria uniforme (generatori pseudocasuali di numeri, su $[0, MAX]$)
			- quindi posso generare una v.a. $X \sim Unif(0, MAX)$
			- assumiamo di avere una v.a. uniforme in $(0, 1)$
			- ora vogliamo generare una v.a. $Y$ con funzione di ripartizione $F$ data
				- $Y := F^{-1}(X) \implies F_{Y} = F$
				- di conseguenza $y_{1} = F^{-1}(x_{1}), \cdots, y_{n} = F^{-1}(x_{n})$
				- questo vale perché $F_{Y}(y) = \mathbb{P}(Y \leq y) = \mathbb{P}(F^{-1}(X) \leq y) = \mathbb{P}(X \leq F(Y)) = F_{X}(F(Y)) = F(Y)$
			- qualunque sia questa $F$, possiamo sempre trovare una v.a. $Y$ che ha tale funzione di ripartizione a partire da $X$ uniforme
			- ora, potrebbe capitare che $F$ sia una f.d.r. non invertibile (caso discreto)
				- ...
			- allora posso generare anche una v.a. che vive in $[0, 1]$: $\frac{X}{MAX} \sim Unif(0, 1)$
				- questo perché ...
	- esponenziale
		- $X \sim Exp(\lambda), \lambda > 0$
		- $f_{X}(x) = \lambda e^{-\lambda x} \mathbb{1}_{[0, +\infty)}(x)$ e $S_{X} = [0, +\infty)$
		- $F_{X}(x) = (1 - e^{-\lambda x}) \mathbb{1}_{(0, +\infty)}(x)$
		- $\mathbb{E}[X] = \frac{1}{\lambda}$ (fare i calcoli)
		- $Var(X) = \frac{1}{\lambda^{2}}$
	- normale o gaussiana
		- importantissima, c'è un teorema che lega l'indipendenza con variabili con queste distribuzioni
		- $X \sim \mathcal{N}(\mu, \sigma^{2})$ e si dimostrerà che $\mu = \mathbb{E}[X]$ e $\sigma^{2} = Var(X)$
		- $f_{X}(x) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{- \frac{(x - \mu)^{2}}{2 \sigma^{2}}}$
		- $F_{X}(x) = \cdots$
		- distribuzione normale standard, importantissima: $X \sim \mathcal{N}(0, 1)$
			- $\phi_{X}(x) = \frac{1}{\sqrt{2 \pi}} e^{- \frac{x^{2}}{2}}$
			- $\Phi_{X}(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{- \frac{y^{2}}{2}} \ dy$
			- integrale di Gauss: $\sqrt{\pi} = \int_{-\infty}^{+\infty} e^{-z^{2}} \ dz$
		- nota bene: se $X \sim \mathcal{N}(\mu, \sigma^{2})$ allora $Z := \frac{X - \mu}{\sigma} \sim \mathcal{N}(0, 1)$
			- questa $Z$ avrà valore atteso 0 e varianza 1
			- dimostriamo che mantiene la stessa legge, ossia che rimane una normale ma di media e varianza diversa
			- questo processo si chiama _standardizzazione_, e si può sempre fare
		- proprietà di $\Phi(x)$
			- $\Phi(0) = 1/2$
			- $\Phi(-x) = 1 - \Phi(x)$

## Domande

## Referenze
