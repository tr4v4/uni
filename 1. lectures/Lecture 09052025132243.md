---
tags:
  - category/lecture
  - status/pending
  - topic/calcolo-delle-probabilità-e-statistica
date: 09-05-2025 13:22:43
teacher: elena.bandini7@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- **catene di Markov**
	- consideriamo sempre una successione di variabili aleatorie, discrete
	- ma non saranno più indipendenti, e non avranno neanche la stessa legge
		- non sono I.I.D., quindi no teoremi limite
	- però hanno una dipendenza specifica, detta _proprietà di Markov_
	- $(X_{n})_{n \in \mathbb{N}}$ successioni di v.a.
	- _processo stocastico_: insieme di variabili aleatorie indicizzate da un certo parametro 
		- può essere
			- a tempo discreto $(X_{n})_{n \in \mathbb{N}}$
			- a tempo continuo $(X_{t})_{t \in \mathbb{R}}$
		- noi consideriamo il primo caso, a tempo discreto
	- noi consideriamo catene di markov discrete
		- $X_{1} \to S_{X_{1}}$
		- ...
		- $X_{i} \to S_{X_{i}}$ supporto finito o infinito numerabile
		- ipotesi che vale sempre: $\exists S : S_{X_{1}} \subseteq S, \cdots, S_{X_{i}} \subseteq S$, con $S$ finito o numerabile
	- definizione catena di Markov: $(X_{n})_{n \in \mathbb{N}}$ successione di v.a. discrete è detta catena di Markov a tempo discreto (esistono anche quelle a tempo continuo) se
		1. $\exists S$ finito o infinito numerabile $: S_{X_{1}} \subseteq S, \cdots, S_{X_{n}} \subseteq S$, chiamato **spazio degli stati**
		2. vale la **proprietà di Markov** $$\forall i, j, i_{n-1}, \cdots, i_{1} \in S \ \ \ \mathbb{P}(X_{n+1} = j | X_{n}=i, X_{n-1}=i_{n-1}, \cdots, X_{1}=i_{1}) = \mathbb{P}(X_{n+1}=j | X_{n}=i)$$
			- in altre parole $$\mathbb{P}(FUT|PRES \cap PASS) = \mathbb{P}(FUT|PRES)$$
			- chiamerò $$\Pi_{ij}(n) = \mathbb{P}(X_{n+1} = j | X_{n}=i) \ \ \ \forall n \in \mathbb{N}$$
	- ipotesi che assumeremo su $(X_{n})_{n \in \mathbb{N}}$, innocue, per semplificare gli esercizi
		1. $|S| = N$, ossia $S$ è finito
		2. catena omogenea nel tempo --> $\Pi_{ij}(n) = \Pi_{ij} \ \ \ \forall n \in \mathbb{N}, \forall i,j \in S$
			- questa matrice fissata allora si dice _probabilità di transizione_ (ad un passo) dallo stato $i$ allo stato $j$, e $$\Pi = (\Pi_{ij})_{i,j=1, \cdots, N} \in \mathbb{R}^{N \times N}$$
	- proprietà, quasi teoremi
		1. $\Pi_{ij} \in [0, 1] \ \ \ \forall i,j \in S$
		2. $\sum\limits_{j=1}^{N} \Pi_{ij} = 1 \ \ \ \forall i \in S$
			- dimostrazione
				- $\sum\limits_{j=1}^{N} \mathbb{P}(X_{n+1}=j|X_{n}=i) = \sum\limits_{j=1}^{N}\frac{\mathbb{P}(X_{n+1}=j, X_{n}=i)}{\mathbb{P}(X_{n}=i)} = 1$ per la formula delle probabilità totali
		- possiamo vedere le righe della matrice come delle densità condizionate
	- rappresentazione grafica consigliata prevede
		- _nodi_, stati
		- _archi_, sui quali riporto la probabilità di transizione tra gli stati
		- quindi, rileggiamo le proprietà in formule a livello grafico
			- $\sum\limits_{j=1}^{N} \Pi_{ij} = 1 \ \ \ \forall i \in S$ --> le probabilità degli archi uscenti da uno stesso nodo devono dare 1
	- definizione di probabilità di transizione in più passi: definiamo **probabilità di transizione in $m$ passi**, con $m \geq 0$, la probabilità condizionata $$\Pi_{ij}^{(m)} = \mathbb{P}(X_{n+m} = j | X_{n} = i)$$
		- osservazione: $\Pi_{ij}^{(0)} = \mathbb{P}(X_{n}=j | X_{n}=i) = \begin{cases} 1 & i=j \\ 0 & i \neq j \end{cases}$ e $\Pi_{ij}^{(1)}$ è la probabilità di transizione a 1 passo
		- legame tra $\Pi$ e $\Pi^{(m)}$
			- dimostrazione
				- $\Pi_{ij}^{(2)}= \mathbb{P}(X_{n+2}=j|X_{n}=i) = \frac{\mathbb{P}(X_{n+2}=j, X_{n}=i)}{\mathbb{P}(X_{n}=i)} = \frac{\sum\limits_{k=1}^{N} \mathbb{P}(X_{n+2}=j, X_{n+1}=k, X_{n}=i)}{\mathbb{P}(X_{n}=i)}$
				- continuo... si usa la proprietà di Markov e l'omogeneità
	- **classe di comunicazione**
		- $i \to j$, esiste un cammino tra $i$ e $j$, quindi un arco con probabilità strettamente positivo
		- $i$ <-> $j$, se esiste un cammino chiuso che passa da $i$ e $j$
		- si definisce classe di comunicazione l'insieme degli stati che verificazione la relazione di equivalenza $i$ <-> $j$
		- è una partizione di $S$
		- se $i$ <-> $j$ allora si dice che $i$ e $j$ comunicano
		- se $C \equiv S$ la catena è detta irriducibile
			- hanno un ruolo fondamentale nel comportamento asintotico
	- **legge delle variabili aleatorie $X_{n}$, $n \in \mathbb{N}$**
		- ci chiediamo le leggi marginali, ogni variabile aleatoria avrà la sua legge
		- nota bene: le probabilità condizionate non dipendono dal tempo, ma le probabilità discrete no --> la legge di $X_{n}$ non dovrà per forza essere uguale a quella di $X_{n+1}$

## Domande

## Referenze
