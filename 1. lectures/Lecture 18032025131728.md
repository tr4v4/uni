---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-delle-probabilità-e-statistica
date: 18-03-2025 13:17:28
teacher: elena.bandini7@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- **variabili aleatorie** - continuo
	- eventi generati da una variabile aleatoria
	- distribuzione di una variabile aleatoria
		- è fondamentalmente la probabilità degli eventi generati dalla variabile aleatoria$
		- nella pratica come trovo questa distribuzione, funzione di probabilità
		- conoscere la distribuzione su un sottoinsieme di $\mathbb{R}$, equivale a conoscere la distribuzione su ogni intervallo $I$ di $\mathbb{R}$
		- **funzione di ripartizione**
			- $F_{X}(x) := \mathbb{P}_{X}((-\infty, x]) = \mathbb{P}(X \leq x)$
			- _variabili aleatorie costanti_
				- $a \in \mathbb{R}, X(w) = a \ \ \ \forall w \in \Omega$
				- $\sigma(X) = \{\Omega, \varnothing\}$
				- $\mathbb{P}_{X}(B) = \mathbb{P}(X \in B) = \begin{cases} 1 & a \in B \\ 0 & a \in B \end{cases}$ che guarda caso è la [[Delta di Dirac]] sul punto $a$, ovvero è $\delta_{a}(B)$
				- quindi $\mathbb{P}_{X}(\cdot) = \delta_{a}(\cdot)$
				- differenza tra funzione indicatrice e delta --> la funzione indicatrice considera delle variabili aleatorie, la delta considera una probabilità (un evento)
			- _variabili indicatrici_
				- $A \subseteq \Omega, X(w) = \mathbb{1}_{A}(w)$
				- fisso $B \subseteq \mathbb{R}$, e ho $\sigma(X) = \{A, A^{C}, \Omega, \varnothing\}$
				- $\mathbb{P}_{X}(B) = \mathbb{P}(X \in B) = \begin{cases} \mathbb{P}(A) & 1 \in B, 0 \notin B \\ \cdots \end{cases}$
				- in realtà possiamo scrivere questa probabilità SEMPRE come un delta di dirac! Perché è una probabilità discreta
					- $= \mathbb{P}(A) \delta_{1}(B) + (1 - \mathbb{P}(A)) \delta_{0}(B)$
				- in generale avremo $\mathbb{P}_{X}(\cdot) = \mathbb{P}(A) \delta_{1}(\cdot) + (1 - \mathbb{P}(A)) \delta_{0}(\cdot)$
				- e questa si chiama distribuzione (o legge) di Bernoulli
			- allora vogliamo passare alla funzione di ripartizione per scrivere in modo compatto ed elegante queste cose
				- $\mathbb{P}_{X}$ contiene tutte le informazioni di $X$, ma è una funzione di insiemi --> è complicata da determinare
				- al posto di scrivere $\mathbb{P}_{X}$, si scrive la funzione di ripartizione
				- l'osservazione base è che $B \subseteq \mathbb{R}$, e quindi se conosco la distribuzione su $B$ la conosco su qualunque intervallo di $\mathbb{R}$
				- definisco: $(\Omega, \mathbb{P})$ spazio di probabilità, con $X: \Omega \to \mathbb{R}$; allora chiamo la funzione di ripartizione di $X$ la funzione $$F_{X}: \mathbb{R} \to [0, 1]$$
					- dove $$F_{X}(x) = \mathbb{P}_{X}((-\infty, x]) = \mathbb{P}(X \leq x)$$
				- ora, _variabili costanti_
					- $\mathbb{P}_{X}(B) = \delta_{a}(B)$
					- allora calcoliamo $F_{X}(x) = \mathbb{P}_{X}((-\infty, x]) = \delta_{a}((-\infty, x]) = \begin{cases} 1 & a \leq x \\ 0 & a > x \end{cases}$
				- ora, _variabili indicatrici_
					- $\mathbb{P}_{X}(B) = \cdots$
					- allora calcoliamo $F_{X}(x) = \mathbb{P}_{X}((-\infty, x]) = \mathbb{P}(A) \delta_{1}((-\infty, x]) + (1 - \mathbb{P}(A)) \delta_{0}((-\infty, x]) = \begin{cases} 1 & x \geq 1 \\ 0 & x < 0 \\ 1 - \mathbb{P}(A) & x \in [0, 1) \end{cases}$
			- **teorema importante**
				- $(\Omega, \mathbb{P})$ spazio di probabilità, $X: \Omega \to \mathbb{R}$, $F_{X}$ funzione di ripartizione, allora valgono le seguenti 4 proprietà:
					1. $F_{X}$ è monotona crescente
					2. $F_{X}$ è continua a destra, ossia $\lim_{y \to x^{+}} F_{X}(y) = F_{X}(x) \ \ \ \forall x \in \mathbb{R}$
					3. $\lim_{x \to +\infty} F_{X}(x) = 1$
					4. $\lim_{x \to -\infty} F_{X}(x) = 0$
				- fondamentale il fatto che vale il viceversa! infatti se ho una funzione $G: \mathbb{R} \to [0, 1]$ che verifica 1, 2, 3, 4, allora $\exists (\Omega, \mathbb{P}), X: \Omega \to \mathbb{R} : G \equiv F_{X}$
				- come si dimostra?
					1. facile, usiamo la monotonia della probabilità
					2. 3, 4, mi serve la stabilità per i limiti monotoni, una proprietà che non abbiamo dimostrato per la probabilità
						- per dimostrarlo quindi devo passare al limite dentro la probabilità
						- questo è un lemma:
							- sia $(\Omega, \mathbb{P})$ spazio di probabilità
							- ho degli eventi $A_{n} \nearrow A$, ovvero $A_{n} \subset A_{n+1}, \bigcup_{n=1}^{+\infty} A_{n} = A$
							- allora vale che $$\lim_{n \to +\infty}\mathbb{P}(A_{n}) = \mathbb{P}(A)$$
							- la stessa cosa vale per $A_{n} \searrow A$
							- provare a dimostrarlo a casa!
					- dimostrare per esempio la 2 con il lemma
						- $\lim_{x \to +\infty} F_{X}(x) = 1 \iff \lim_{x \to +\infty} \mathbb{P}_{X}((-\infty, x]) = \mathbb{P}_{X}(\mathbb{R})$
						- devo applicare il lemma: cerco dei $B_{n}$ tali che $B_{n} \nearrow \mathbb{R}$, ovvero $B_{n} \subseteq B_{n+1}, \ \ \bigcup_{n=1}^{+\infty} B_{n} = \mathbb{R}$
						- scegliamo come $B_{n}$ proprio i $(-\infty, x]$, ma dobbiamo capire come trasferire la $n \in \mathbb{N}$ nelle $x \in \mathbb{R}$
						- allora $B_{n} = (-\infty, n], \ \ \ n \in \mathbb{N}$
						- allora $\lim_{n \to +\infty} \mathbb{P}_{X}(B_{n}) = \mathbb{P}_{X}(\mathbb{R}) = 1$
						- concludo osservando $F_{X}(\cdot)$ è monotona crescente e quindi ammette limite (il limite è unico)
							- se trovo il limite sui naturali ce l'ho anche sui reali! e dev'essere lo stesso
						- quindi $\lim_{x \to +\infty} F_{X}(x) = 1$
				- si può dimostrare (si usa il lemma) che esiste anche il limite da sinistra, e vale $$\lim_{y \to x^{-}} F_{X}(y) = \mathbb{P}(X < x)$$
	- noi sappiamo che
		- $\mathbb{P}(X \leq x) = \mathbb{P}(X < x) + \mathbb{P}(X = x)$
		- ma questo significa che, per le proprietà di prima, $F_{X}(x) - F_{X}(x^{-}) = \mathbb{P}(X = x)$
		- ossia la funzione di ripartizione salta soltanto in corrispondenza dei valori di $x$
		- possiamo leggere la probabilità di $X = x$ nei salti, ossia nei $\Delta F_{X}$
		- formalmente: la probabilità di ogni intervallo si può scrivere in termini della $F_{X}$
			- ossia, preso l'intervallo:
			- $(a, b]$, allora $$\mathbb{P}_{X}((a, b]) = F_{X}(b) - F_{X}(a)$$
			- $[a, b)$, allora $$\mathbb{P}_{X}([a, b)) = F_{X}(b^{-}) - F_{X}(a^{-})$$
			- $(a, b)$, allora $$\mathbb{P}_{X}((a, b)) = F_{X}(b^{-}) - F_{X}(a)$$
			- $[a, b]$, allora $$\mathbb{P}_{X}([a, b]) = F_{X}(b) - F_{X}(a^{-})$$
- **variabili aleatorie discrete**
	- sono variabili aleatorie che assumono un numero finito o infinito numerabile di valori
	- nella pratica vuol dire che
		- o l'immagine è finita (o numerabile)
		- o è quasi certamente costante
	- formalmente: $X: \Omega \to \mathbb{R}$ è una variabile aleatoria discreta se
		- $\Omega$ è discreto, ossia $\Im(X)$ finita o numerabile
		- $\Omega$ è non discreto, ossia $\exists S_{X} \subseteq \Im(X)$ con $S_{X}$ finito o numerabile tale che $\mathbb{P}(X \in S_{X}) = 1$, $X \in S_{X}$ quasi certamente
	- definizione di funzione di distribuzione di probabilità di $X$

## Domande

## Referenze
