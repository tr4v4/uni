---
tags:
  - category/lecture
  - status/pending
  - topic/calcolo-numerico
date: 14-10-2024 13:19:54
teacher: davide.evangelista5@unibo.it
mod: 2
---
# Lezione
---
## Concetti
- **approssimazione** (domani facciamo ottimizzazione)
	- il progetto sarà su approssimazione+ottimizzazione, in più ci sono esercizi di approfondimento facoltativi
	- matplotlib: serve per l'esposizione dei risultati, per fare i grafici
	- prima di affrontare l'approssimazione facciamo _caricamento dei dati e visualizzazione_ con `pandas`
		- fondamentalmente è machine learning! faremo modelli di previsione per prevedere il futuro a partire da dati in input
	- plottati i dati del covid osserviamo che
		1. i dati seguono l’andamento di una **curva** relativamente complessa, ma con un pattern chiaramente riconoscibile
		2. i dati _non_ sono disposti in maniera precisa lungo la curva, ma mostrano un comportamento casuale: sono affetti da _rumore_
	- quindi presi dei dati, vogliamo dal rumore trovare un pattern attraverso un algoritmo che non segua i dati alla perfezione, ma li approssimi per capire la tendenza e prevedere il futuro!
	- modelli di approssimazione e minimi quadrati
		- definizioni
			- variabili indipendenti, o variabili di input, indicate con $x$
			- variabili dipendenti, o variabili di output, indicate con $y$
			- set di dati (_dataset_) è una collezione di coppie di valori $\{(x_{1}, y_{1}), \cdots, (x_{n}, y_{n})\}$ tra loro associati
		- concetti di assunzione:
			1. i dati seguono una curva complessa ma con un pattern riconoscibile;
			2. i dati non sono disposti lungo la curva in maniera esatta, ma c'è del rumore che fa smuovere i dati rispetto alla curva;
		- formalizzazione:
			1. $\exists f(x) : y \approx f(x)$
			2. $\exists e : y = f(x) + e \ \ \ \forall x$
		- per semplificazione assumiamo che $e$ sia _gaussiana_
		- assunte queste due cose, un **metodo di approssimazione** è un qualunque algoritmo che, fissato un modello $f_{\theta}(x)$ dipendente da un'insieme di parametri $\theta$, calcola il valore dei parametri $\theta$ tali che $f_{\theta}(x)$ sia il più possibile vicina a $f(x)$
		- _problema test_: per fare _benchmarking_ ci costruiamo a mano dei dati in modo tale da ricavare semplicemente $f(x)$, e vedere se gli algoritmi approssimano $f(x)$ in modo corretto
			- quindi:
				1. specifichiamo una funzione $f(x)$
				2. generiamo del rumore gaussiano $e$
			- imponiamo che $f(x)$ sia una funzione polinomiale, in particolare un polinomio nella variabile $x$ di grado $d$: $$f(x) = a_{0} + a_{1}x + a_{2}x^{2} + \cdots + a_{d}x^{d} = \sum\limits_{k=0}^{d} a_{k}x^{k}$$
			- ricordiamo che un polinomio di grado $d$ è completamente determinato dai suoi coefficienti $a_{0}, a_{1}, \cdots, a_{d}$
			- codice python
		- **approssimazione ai minimi quadrati**
			- assumiamo che la funzione che vogliamo approssimare sia un polinomio $$f_{\theta}(x, \alpha) = \sum\limits_{k=0}^{d} a_{k}x^{k}$$
			- vogliamo trovare l'$\alpha$ che approssimi la funzione $f(x)$ originaria
			- trasformiamo il problema nella ricerca dei minimi quadrati
			- giocare con tutti i parametri e con le fattorizzazioni (Cholesky e SVD)
				- più il rumore è alto più la curva approssimante "vibra"
				- più il grado del polinomio approssimante è alto più la curva di approssimazione "vibra"
				- con pochi dati in input la curva approssimata tende a "vibrare" molto
				- si capisce il trade-off tra _underfit_ e _overfit_

## Domande

## Referenze
