---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-numerico
date: 22-10-2024 09:23:39
teacher: davide.evangelista5@unibo.it
mod: 2
---
# Lezione
---
## Concetti
- ottimizzazione di dati
	- ricordiamo che noi analizziamo solo i casi di $f$ _smooth_ e $\Omega$ _svincolati_, di solito su $f$ _lineari_ (ma guarderemo anche casi quadratici)
	- significato dei minimi locali e globali nel contesto dell'ottimizzazione --> troviamo una soluzione buona localmente, se la cambiamo poco peggiore, ma se la cambiamo radicalmente migliore drasticamente
		- non è computazionalmente efficiente distinguere i locali dai globali
		- definizione formale di minimi e massimi locali e globali
	- funzioni convesse e non convesse
		- matematicamente c'è una definizione formale
		- l'importante è capire l'immagine: _presi due punti del grafico e collegati da un segmento, il grafico della funzione starà sempre sotto di esso_
		- le funzioni convesse o concave sono molto comode per questi problemi di ottimizzazione, mentre quelle non convesse e non concave per niente
		- caratterizzazione delle funzioni convesse
			- se $f(x)$ è sufficientemente liscia è possibile distinguere funzioni convesse da non convesse calcolandone l'[[Matrice hessiana|Hessiana]]
			- teorema: una funzione $f \in C^{2}(\mathbb{R}^{n})$ è convessa $\iff$ la matrice hessiana $H_{f}(x_{0}) = (\nabla^{2}f(x_{0}))_{i,j} \ \ \forall x_{0} \in \mathbb{R}^{n}$ è semi-definita positiva, ossia $\forall x \in \mathbb{R}^{n} \ \ \ x^{T}H_{f}(x_{0})x \geq 0$
		- il motivo per cui ci interessano le funzioni convesse dipende dal seguente teorema
			- teorema: sia $f: \mathbb{R}^{n} \to \mathbb{R}$ convessa, allora tutti i $x^{*}$ punti di minimo locale sono anche minimi globali
	- un'altra ipotesi adottata in ottimizzazione è che la funzione obiettivo $f$ sia oltre che convessa anche _coerciva_, ovvero che $\lim_{\|x\| \to \infty} f(x) = +\infty$
		- questa ipotesi ci assicura che esiste per $f$ almeno un minimo locale, che per via della convessità è anche globale
	- ricapitolando: _tutte le funzioni obiettivo convesse e coercive hanno almeno un minimo e questo è globale_
	- da ora in avanti assumeremo sempre che $f(x)$ sia convessa e coerciva
		- nota bene: tutti i problemi dei minimi quadrati sono convessi e coercivi!
	- calcolo di convessità e coercività
		- prendiamo $f(x) = (x-1)^{2} + e^{x}$ --> $f'(x) = 2(x-1) + e^{x}$ e $f''(x) = 2 + e^{x}$
		- notiamo che $f''(x) \geq 0 \ \ \ \forall x \in \mathbb{R}$, per cui $f(x)$ è convessa
		- per la coercività ci basta dimostrare che $\lim_{x \to +\infty} f(x) = \lim_{x \to -\infty}f(x) = +\infty$
	- estremi relativi e punti stazionari
		- _condizione necessaria del primo ordine_ --> sul gradiente
			- definizione: un punto $x^{*}$ è stazionario se $\nabla f(x^{*}) = 0$
			- teorema: ogni punto di minimo di $f$ è un punto stazionario ([[Teorema di Fermat]])
			- è il teorema più debole
			- però se $f$ è convessa e coerciva, allora ogni soluzione di $\nabla f(x) = 0$ è un punto di minimo globale
		- _condizione necessaria del secondo ordine_ --> sull'hessiana
			- teorema: se $x^{*}$ è minimo, allora $\nabla f(x^{*}) = 0$ e $H_{f}(x^{*})$ è semi-definita positiva, ovvero $x^{T}H_{f}(x^{*})x \geq 0 \ \ \ \forall x \in \mathbb{R}^{n}$
		- _condizione sufficiente del secondo ordine_ --> sull'hessiana
			- teorema: se $x^{*}$ è stazionario e $H_{f}(x^{*})$ è definita positiva (non semi), allora $x^{*}$ è un punto di minimo di $f$
			- se noi sappiamo che, in quanto $f$ convessa, $H_{f}(x^{*})$ è sempre semi-definita positiva, quindi ogni soluzione $x^{*}$ del punto 1 è un punto di minimo tranne per quei punti per cui $H_{f}(x^{*})$ è singolare (determinante diverso da 0)
	- esercizio su questo da fare
	- **metodo di discesa del gradiente**
		- rientra nei metodi di ricerca in linea
		- scelto un termine $x_{0} \in \mathbb{R}^{n}$ si considera l'iterazione $$x_{k+1} = x_{k} + \alpha_{k}p_{k}$$
		- dove $\alpha_{k} > 0$ è detto _step-size_ o _learning-rate_, mentre $p_{k} \in \mathbb{R}^{n}$ è un vettore detto _direzione di discesa_, scelto tale che $f(x_{k+1}) \leq f(x_{k})$ --> l'algoritmo si muove verso la direzione del minimo per ogni iterato $k \in \mathbb{N}$
		- vogliamo che $x^{*} = \lim_{k \to \infty} x_{k}$ con $x^{*}$ è punto di minimo
		- definizione: una direzione di discesa $p_{k}$ se esiste $\alpha_{k}$ tale che $f(x_{k} + \alpha_{k}p_{k}) \leq f(x_{k})$
		- teorema: $p_{k}$ è di discesa per $f(x)$ in $x_{k}$ se $p_{k}^{T} \nabla f(x_{k}) \leq 0$
			- allora è facile, perché se scegliamo $p_{k} = -\nabla f(x_{k})$ otteniamo $p_{k}^{T} \nabla f(x_{k}) = - \|\nabla f(x_{k})\|_{2}^{2} \leq 0$
		- sceglieremo sempre $p_{k}$ come l'anti-gradiente
		- l'algoritmo è facile $$\begin{cases} x_{0} \in \mathbb{R}^{n} \\ x_{k+1} = x_{k} - \alpha_{k} \nabla f(x_{k}) \end{cases}$$
			- dove $\alpha_{k}$ lo sceglieremo noi
		- questo è il metodo di discesa del gradiente
		- esercizio per casa (giocare con parametri dell'algoritmo)
		- definiamo dei criteri di arresto per fermare l'algoritmo quando si raggiunge un risultato accettabile
			1. $\|\nabla f(x_{k})\|_{2} \leq tolf$ (di solito $tolf = 10^{-6}$)
			2. $\|x_{k+1} - x_{k}\|_{2} \leq tolx$, perché ci vogliamo arrendere quanto la funzione è troppo piatta
		- scelta del passo $\alpha_{k}$
			- troppo piccolo --> converge lentamente
			- troppo grande --> addirittura diverge, rimbalzando sulle pareti della funzione!
			- teorema: se si sceglie un $\alpha_{k}$ che soddisfa le **condizioni di Wolfe**, in particolare la prima nota come **condizione di Armijo**
				- ci dice che $f(x_{k+1}) \leq f(x) - c_{1}\alpha_{k}\|\nabla f(x_{k})\|_{2}^{2} \ f(x_{k})$
			- per applicare il teorema c'è l'algoritmo di backtracking
				- si abbassa $\alpha_{k}$ finché non soddisfa Armijo
				- si dimostra che termina sempre
		- si usa backtracking per scegliere $\alpha_{k}$ ad ogni passo
			- notare che ha un costo
		- esercizio da fare, confrontare i tempi con backtracking e non (per vedere trade-off tra numero di iterazioni e tempo d'esecuzione)

## Domande

## Referenze
