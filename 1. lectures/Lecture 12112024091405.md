---
tags:
  - category/lecture
  - status/finished
  - topic/calcolo-numerico
date: 12-11-2024 09:14:05
teacher: elena.loli@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- imaging
	- ripasso
	- dobbiamo regolarizzare
		- TSVD --> troppo costosa, le immagini sono matrici giganti
		- Tikhonov --> il problema diventa $$\min_{x} {\|Ax - y^{\delta}\|_{2}}^{2} + \lambda {\|x\|_{2}}^{2}$$
			- da cui risolvo le equazioni normali $$(A^{T}A + \lambda I)x = A^{T}y^{\delta}$$
			- è la condizione del primo ordine, per cui se è $x$ è minimo allora l'equazione è soddisfatta per quell'$x$
			- ma se la funzione è convessa, e lo è, allora le condizioni sono necessarie e sufficienti --> le soluzioni dell'equazione sono minimi, e anche globali (perché è strettamente convessa)!
			- anche qui si può usare il principio di massima discrepanza
		- Variazione Totale (TV) --> $TV(x) = \|\nabla (x)\|_{1}$, dove il gradiente dell'immagine $x$ è calcolato con una _formula alle differenze_
			- c'è la formula, e non essendo differenziabile in $(0, 0)$ si aggiunge un parametro $\beta > 0$
			- _il gradiente di un'immagine è un indice fondamentale dell'imaging_
				- infatti ogni immagine (in scala di grigi) può essere vista come una funzione (discreta) in 3 dimensioni

## Domande

## Referenze
