---
tags:
  - category/lecture
  - status/finished
  - topic/algebra-e-geometria
date: 07-03-2024 11:16:04
teacher: marta.morigi@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- concetti discussi
	- generatori
	- indipendenza lineare
	- base
	- dimensione
- nota: sono legati tra loro! Si veda teorema GEL
- utilizzo dell'algoritmo di Gauss _in modo diretto_, non solo per risolvere sistemi lineari (ci è chiesto all'esame)
	- possiamo farlo grazie a due teoremi
		1. le operazioni elementari sulle righe di una matrice non cambiano il sottospazio generato dalle righe della matrice
			- dimostrazione: _basta osservare che le operazioni elementari coincidono con delle combinazioni lineari_! Quando facciamo $R_{i} = \alpha R_{i} (\alpha \neq 0)$, per esempio, stiamo moltiplicando per uno scalare $R_{i}$; e quando facciamo $R_{i} = R_{i} + \alpha R_{j}$ stiamo facendo una combinazione lineare di $1 \cdot R_{i} + \alpha R_{j} + 0 \cdot R_{...}$
		2. le righe non nulle di una matrice a scala sono linearmente indipendenti
	- applicazioni:
		- ci permette di trovare una base del sottospazio generato da alcuni vettori di $\mathbb{R}^{n}$
			- esempio $W = \langle (1, 1, 3, 0), (2, 2, 5, 1), (1, 1, 4, -1) \rangle \leq \mathbb{R}^{4}$
				- trovare una base di $W$, si potrebbe fare usando la definizione di base e sfruttando la capacità di togliere un vettore alla volta fino a trovare la base --> ma è lungo
				- allora sfruttiamo i teoremi di prima e _mettiamo i vettori in riga_
					- $\begin{pmatrix} 1 & 1 & 3 & 0 \\ 2 & 2 & 5 & 1 \\ 1 & 1 & 4 & -1 \end{pmatrix}$
					- otteniamo che $W$ è anche generato da $\{(1, 1, 3, 0), (0, 0, -1, 1)\}$, che sono anche linearmente indipendenti (per il secondo teorema) $\implies$ ho scoperto una base di $W$
					- di conseguenza la dimensione di $W$ è 2
				- differenze di metodi: con il metodo dell'eliminazione continua si ottiene un sottoinsieme di $W$, invece con questo, molto più rapido, otteniamo sempre una base ma che non è sottoinsieme di $W$
			- osservazioni: se $V = \langle v_{1}, \cdots, v_{m} \rangle$ costruiamo la matrice di vettori in riga, si ottiene $V = \langle v_{1}, \cdots, v_{m} \rangle = \langle w_{1}, \cdots, w_{k} \rangle$ per il primo teorema, e per il secondo $w_{1}, \cdots, w_{k}$ sono indipendenti $\implies \beta = \{w_{1}, \cdots, w_{k}\}$ è base di $V$ e la sua dimensione è $k$
				- schema carino del processo di trasformazione
				- ragionando possiamo anche decidere se $v_{1}, \cdots, v_{m}$ sono indipendenti o meno: parto da $m$ vettori, li riduco a scala e ottengo $w_{1}, \cdots, w_{k}$; ho che se $k < m$ allora $v_{1}, \cdots, v_{m}$ sono dipendenti! Perché nello spazio vettoriale $V$ con dimensione $k$ possiamo avere al massimo $k$ vettori indipendenti (da teorema del completamento, un insieme di vettori linearmente indipendenti ha cardinalità $\leq k$); se invece $k = m$, allora $v_{1}, \cdots, v_{m}$ sono (sicuramente) indipendenti (usiamo il teorema GEL)
				- altro ragionamento, possiamo completare una base di $V$ a una base di $\mathbb{R}^{n}$: guardiamo da esempio di prima
					- una base di $W$ è $\{(1, 1, 3, 0), (0, 0, -1, 1)\}$, completare $W$ vuol dire completarla a una base di $\mathbb{R}^{4}$, ovvero trovare un sovrainsieme di $W$ che sia base di $\mathbb{R}^{4}$
					- $\mathbb{R}^{4}$ ha dimensione 4, quindi per GEL basta avere 4 vettori linearmente indipendenti: 2 vettori li abbiamo già, sono di $W$
						- dal secondo teorema scopriamo che di una matrice a scala se si aggiungono righe in modo da mantenere la scala otteniamo vettori linearmente indipendenti
						- per cui se prima abbiamo $$\begin{pmatrix} 1 & 1 & 3 & 0 \\ 0 & 0 & -1 & 1 \end{pmatrix}$$
						- ci basta aggiungere due righe random nelle posizioni che mantengono la scalatura $$\begin{pmatrix} 1 & 1 & 3 & 0 \\ 0 & 3 & -7 & 0 \\ 0 & 0 & -1 & 1 \\ 0 & 0 & 0 & 48 \end{pmatrix}$$
						- da cui ricaviamo la base $$\beta = \{(1, 1, 3, 0), (0, 3, -7, 0), (0, 0, -1, 1), (0, 0, 0, 48)\}$$
							- che per GEL è base di $\mathbb{R}^{4}$
							- mi raccomando specificare che la risposta non è la matrice, ma l'insieme dei vettori come sue righe
		- aumentiamo il grado di difficoltà, dall'esercizio di prima
			- dimostrare che $A = \{(2, 2, 5, 1), (1, 1, 4, -1)\}$ è base di $W$ e completarla a una base $D$ di $\mathbb{R}^{4}$
				- ho che $a_{1}, a_{2}$ (i vettori di $A$) sono linearmente indipendenti, perché non sono uno multiplo dell'altro; so anche che $W$ ha dimensione 2 (da prima); per cui per il teorema GEL $A$ è base di $W$
				- per completarli (e possiamo farlo per il teorema del completamento) stavolta però non abbiamo il trucchetto dei pivot
					- sappiamo che $\mathbb{R}^{4} = \langle W, v_{1}, v_{2} \rangle$ dove $W$ è basato, $v_{1}$ e $v_{2}$ sono i vettori aggiunti per completare $W$ a $\mathbb{R}^{4}$
					- ma allora $\mathbb{R}^{4} = \langle w_{2}, w_{3}, v_{1}, v_{2} \rangle$, e per GEL $\{w_{2}, w_{3}, v_{1}, v_{2}\}$ sono base di $\mathbb{R}^{4}$
			- esercizio
				- fondamentalmente l'idea è: _se quando ci viene chiesto di completare un generatore a uno spazio, se non riusciamo a trovare i pivot, riduciamo i vettori a scala così da vedere i pivot mancanti, e questi possono essere aggiunti ai vettori non "scalati"_
- idea delle applicazioni lineari
	- sia $V$ spazio vettoriale e $\beta = \{v_{1}, \cdots, v_{n}\}$ base _ordinata_ di $V$, e un $v \in V$, le coordinate di $v$ rispetto alla base $\beta$ sono $$(v)_{\beta} = (\lambda_{1}, \cdots, \lambda_{n})$$ con $v = \lambda_{1}v_{1} + \cdots + \lambda_{n}v_{n}$
		- consideriamo ora la funzione $f_{\beta}: V \to \mathbb{R}^{n}$ t.c. $v \to (v)_{\beta}$, ovvero che dato un vettore ci associa le sue coordinate, si ha che
			- $f_{\beta}$ è iniettiva e suriettiva e rispetta la somma e il prodotto per scalari
			- in matematichese: è [[Isomorfismo|isomorfismo]] di spazi vettoriali
				- come sappiamo, dalle proprietà degli isomorfismi, possiamo lavorare in $V$ passando alle coordinate e lavorare in $\mathbb{R}^{n}$, poi si torna a $V$
		- esercizio:
			- siano $w_{1} = x^{4} + 2x^{3} + 3x^{2} + 4, w_{2} = 2x^{4} + 3x^{3} + x^{2} + x + 3, w_{3} = 2x^{3} + 10x^{2} + x + 1$
			- stabilire se $w_{1},w_{2}, w_{3}$ sono linearmente indipendenti e se possibile completare $\{w_{1}, w_{2}, w_{3}\}$ a una base di $\mathbb{R}_{4}[x]$
			- sappiamo che $\beta = \{x^{4}, x^{3}, x^{2}, x, 1\}$ è la base canonica di $\mathbb{R}_{4}[x]$
			- allora passiamo alle coordinate, per cui $(w_{1})_{\beta} = (1, 2, 3, 0, 4), (w_{2})_{\beta} = (2, 3, 1, 1, 3), (w_{3})_{\beta} = (0, 2, 10, 1, 1)$
			- sono proprio i vettori di prima, per cui al posto di lavorare in $V$ passiamo a lavorare in $\mathbb{R}^{5}$[^1], e il resto dell'esercizio è come quello fatto sul quaderno in precedenza
			- per cui sappiamo che $\{v_{1}, v_{2}, v_{3}, (0, 0, 7, 1, 1), (0, 0, 0, 0, 2)\}$ sono linearmente indipendenti e generano $\mathbb{R}^{5} \implies$ è base di $\mathbb{R}^{5}$
			- allora torniamo a $\mathbb{R}_{4}[x]$, e scopriamo che $w_{1}, w_{2}, w_{3}$ sono indipendenti lineari e una base di $\mathbb{R}_{4}[x] = \{w_{1}, w_{2}, w_{3}, 7x^{2}+x+1, 2\}$

## Domande

## Referenze
[^1]: è una cosa che già facevo per risolvere le uguaglianze tra polinomi negli esercizi di tutorato