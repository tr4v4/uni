---
tags:
  - category/lecture
  - status/ongoing
  - topic/sistemi-operativi
date: 17-10-2024 09:16:31
teacher: renzo.davoli@unibo.it
mod: 1
---
# Lezione
---
## Concetti
- quine come sistema per verificare la turing-completezza di un linguaggio
- concorrenza
	- recap
		- concorrenza reale: multiprocessing;
		- concorrenza apparente: multiprogramming;
	- notazione per descrivere processi concorrenti
		- tutto scritto in pseudocodice (anche all'esame)
	- interazioni tra processi
		- si classificano i processi in base a quanto sono consapevoli uno dell'altro
		- processi ignari uno dell'altro si dicono _indipendenti_
			- come interagiscono:
				- competendo per le stesse risorse;
				- sincronizzandosi nel loro utilizzo;
			- il sistema operativo deve arbitrare questa competizione, fornendo meccanismi di sincronizzazione
		- processi che si conoscono "indirettamente"
		- processi che si conoscono "direttamente"
	- modelli di interazione:
		- _memoria condivisa_ - più processi che condivisono la memoria (stesse variabili) (ovviamente non quelle dei record di attivazione nello stack, quelle sono sempre locali)
			- comunicazione tramite sincronizzazione
		- _memoria privata_ - i processi non condividono la memoria
			- sincronizzazione tramite comunicazione (messaggi `ACK` anche qui)
	- proprietà di un programma
		- definizione: un'espressione logica che rimane vera per ogni possibile storia di esecuzione del programma
		- tipologie:
			- _safety_ (non security) - mostrano che il programma (se avanza) va nella direzione voluta, che non fa qualcosa di sbagliato
			- _liveness_ - il programma avanza, non si ferma (è vitale), che arrivi in fondo alla sua esecuzione
		- esempio:
			- _consensus_, dalla teoria dei sistemi distribuiti: si consideri un sistema con $N$ processi; all'inizio ogni processo propone un valore, e alla fine tutti i processi si devono accordare su uno dei valori proposti
			- safety --> se un processo decide, deve decidere uno dei valori proposti; se due decidono, devono decidere lo stesso valore;
			- liveness --> prima o poi ogni processo corretto prenderà una decisione (non va in crash);
		- nei programmi sequenziali: safety = correttezza dello stato finale; liveness = terminazione del programma;
		- nei programmi concorrenti:
			- safety = i processi non devono interferire tra di loro nell'accesso alle risorse condivise (per quelli che le condividono)
			- liveness = i meccanismi di sincronizzazione usati non devono prevenire l'avanzamento del programma (un programma non può attendere un tempo indefinito prima di poter accedere a una risorsa condivisa)
		- **mutua esclusione** (safety)
			- l'accesso a una risorsa è mutualmente esclusiva se ad ogni istante un processo può accedere a quella risorsa
		- **deadlock** (stallo)
			- la mutua esclusione permette di risolvere il problema della non interferenza, ma può causare il blocco permanente dei processi
			- la assenza di deadlock è una proprietà di safety (anche se è discusso)
			- esempio dell'incrocio stradale
			- esempio di processi e risorse
			- la soluzione nei sistemi reali è uccidere uno dei processi
		- **starvation**
			- è quando un processo non può accedere a una risorsa perché è sempre occupata
			- l'assenza di starvation è una proprietà di liveness
			- esempio della coda a uno sportello e continuano ad arrivare gente che salta la fila
			- differenza con deadlock:
				- nel deadlock non c'è modo di uscire;
				- con la starvation la cosa si può risolvere autonomamente;
			- esempio di processi e risorse
	- vediamo come garantire mutua esclusione, assenza di deadlock e starvation
		- **azioni atomiche**
			- azioni che vengono compiute in modo indivisibile: o tutto o niente;
			- parallelismo reale --> si garantisce che l'azione non interferisca con altri processi durante la sua esecuzione
			- parallelismo apparente --> l'avvicendamento (context-switching) fra i processi avviene prima o dopo l'azione, che quindi non può interferire con essa
			- le singole istruzioni del linguaggio macchina sono azioni atomiche
				- parallelismo apparente --> l'interrupt viene eseguito prima o dopo un'istruzione, mai durante;
				- parallelismo reale --> la politica di arbitraggio del bus garantisce che una delle due venga servita per prima e l'altra successivamente;
			- in genere sequenze di singole istruzioni del linguaggio macchina non sono azioni atomiche
			- nel linguaggio C
				- dipende dal processore e dal codice generato dal compilatore
				- tipo `a = 0` con `int a` è normalmente atomico
				- `a = 0` con `long long a` invece non è normalmente atomico (nei processori RISC bisogna assegnare 0 nella parte alta e nella parte bassa, quindi sono due istruzioni atomiche)
			- nei compiti di concorrenza:
				- assumiamo che in ogni istante vi possa essere al massimo un accesso alla memoria alla volta
				- l'_unica cosa atomica che consideramo è l'assegnamento di una costante a una variabile_
				- come notazione per azioni atomiche usiamo `< statement atomico >`
				- esempio di interleaving di azioni atomiche
		- non-interferenza
			- se le sequenze di istruzioni non vengono eseguite in modo atomico, come possiamo garantire la non-interferenza?
			- idea generale: specifichiamo che certe parti del programma sono speciali, ossia devono essere eseguite in modo atomico (senza interruzioni) --> in mutua esclusione
			- non basta la mutua esclusione
			- il meccanismo implementato è chiamato **sezione critica**: la parte di un programma che utilizza una o più risorse condivise
			- obiettivi
				- _mutua esclusione_
				- _no deadlock, no starvation_
				- _no attese non necessarie_ -> un processo attende altri solo se questi devono usare una sezione critica attualmente occupata dal primo
			- notazione per indicare sezioni critiche `[enter cs] statement critico [exit cs]`
			- dobbiamo creare questi costruitti perché il S.O. non può capire da solo cosa sia una sezione critica
				- gli dobbiamo indicare cosa può essere eseguito in parallelo e cosa dev'essere eseguito in modo atomico
			- problema della sezione critica: bisogna realizzare $N$ processi di una forma specificata (da inserire) in modo che valga:
				1. _mutua esclusione_ - solo un processo dentro la CS fra tutti quelli che hanno una CS per la stessa risorsa condivisa
				2. _assenza di deadlock_
				3. _assenza di delay non necessari_ - un processo fuori dalla CS non deve ritardare l'ingresso della CS da parte di un altro processo
				4. _assenza di starvation_ - ogni processo che lo richiede, prima o poi entra nella CS
			- approcci per implementare il meccanismo della critical section
				- software
					- `enter cs` e `exit cs` si implementa con una libreria
					- soggetto a errori
					- costoso in termini di esecuzione (busy waiting)
					- interessante didatticamente
				- hardware
					- utilizzano istruzioni speciali del linguaggio, progettate apposta
					- efficienti
					- non adatte come soluzioni general-purpose
		- approccio per implementare CS
			- basati su supporto nel SO o nel linguaggio
			- esempi:
				- semafori (memoria condivisa)
				- monitor (memoria condivisa)
				- message passing (memoria privata)
	- **algoritmo di Dekker**, pubblicato da Djikstra (1965)
		- algoritmo basato per la mutua esclusione
		- la soluzione è sviluppata in fasi, per cui anche noi seguiremo questo approccio
		- fasi:
			- 1
				- supponiamo di avere due processi
				- fanno busy waiting finché non è il loro turno
				- quando è il loro turno nella CS assegnano il turno all'altro processo
				- è garantita la mutua esclusione
				- ma non rispetta l'assenza di delay non necessari
			- 2
				- sembra funzionare, ma viola la mutua esclusione della sezione critica
			- 3
				- provoca deadlock
			- 4
				- provoca starvation
		- da queste 4 fasi però si imparano delle cose
			- il tentativo 1 è ideale per "rompere la simmetria" dei tentativi 3 e 4
			- altre cose
		- algoritmo di Dekker
		- dimostrazione delle proprietà rispettate
			- mutua esclusione:
				- per assurdo: supponiamo che $P$ e $Q$ siano in CS contemporaneamente
				- implica che `needp` e `needq` siano entrambe vere
				- uno dei due entra per primo, supponiamo sia $Q$
				- `needq` sarà `true` fino a quano `Q` non esce dalla CS
				- $P$ entra nella CS mentre $Q$ è nella CS, significa che esiste un istante temporale in cui `needq = false` e $Q$ è in CS --> ASSURDO!
			- assenza di deadlock:
				- per assurdo supponiamo che né $P$ né $Q$ possano entrare in CS
				- $P$ e $Q$ devono essere bloccati nel primo `while`
				- esiste un istante $t$ dopo di che `needp` e `needq` sono sempre`true`
				- supponiamo che all'istante $t$ `turn = Q` (non può essere contemporaneamente anche a `P`)
				- l'unica modifica a `turn` può avvenire solo quando `Q` entra in CS
				- dopo $t$, `turn` resterà sempre uguale a `Q`
				- `P` entra nel primo ciclo, e mette `needp = false` --> ASSURDO!
			- assenza di ritardi non necessari:
				- se `Q` sta eseguendo codice non critico, allora `needq = false`
				- allora `P` può entrare nella CS
			- assenza di starvation:
				- se `Q` richiede di accedere alla CS --> `needq = true`
				- se `P` sta eseguendo codice non critico --> `Q` entra
				- se `P` sta eseguendo il resto del codice, prima o poi ne uscirà e metterè il turno a `Q`, quindi `Q` potrà entrare
	- **algoritmo di Peterson**
		- più semplice e lineare di quello di Dekker
		- più facilmente generalizzabile al caso di processi multipli (infatti Dekker generalizzato a $N$ processi è difficilissimo), e non ha busy waiting come Dekker

## Domande

## Referenze
